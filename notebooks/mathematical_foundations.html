
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Imports &#8212; Mathematics</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      <h1 class="site-logo" id="site-title">Mathematics</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Thank you for visiting!
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../nbs/Sets.html">
   Sets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nbs/ComplexNumbers.html">
   Complex Numbers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nbs/NumberTheory.html">
   Number Theory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nbs/AlgorithmicNumberTheory.html">
   Algorithmic Number Theory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nbs/ModularArithmetic.html">
   Modular Arithmetic
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nbs/Polynomials.html">
   Polynomials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nbs/ConicSections.html">
   Conic Sections
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nbs/Structures.html">
   Structures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nbs/Groups.html">
   Groups
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nbs/Fields.html">
   Fields
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nbs/LinearAlgebra.html">
   Linear Algebra
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Modeling
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../nbs/RandomWalks.html">
   Random Walks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nbs/DigitalSignalProcessing.html">
   Digital Signal Processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nbs/DifferentialEquations.html">
   Differential Equations
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Blockchain
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../nbs/PythonBlockchain.html">
   Python Blockchain
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/notebooks/mathematical_foundations.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/davefriedman01/Resources"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/davefriedman01/Resources/master?urlpath=tree/docs/notebooks/mathematical_foundations.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Imports
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#table-of-contents">
   Table of Contents
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-wiki">
   Data Wiki
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-i-o">
   Data I/O
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#descriptive-data-analysis-and-summary-statistics">
   Descriptive Data Analysis and Summary Statistics
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#measures-of-central-tendency-wiki-or-averages-wiki">
     Measures of Central Tendency Wiki or Averages Wiki
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#pythagorean-means-wiki">
       Pythagorean Means Wiki
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#measures-of-dispersion-wiki">
     Measures of Dispersion Wiki
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#proximity-measures-similarity-and-dissimilarity">
     Proximity Measures (Similarity and Dissimilarity)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#jaccard-proximity-measure">
       Jaccard Proximity Measure
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cosine-proximity-measure">
       Cosine Proximity Measure
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#distance-measures-and-metrics">
       Distance Measures and Metrics
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mi-mutual-information">
       MI Mutual Information
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-preprocessing-and-feature-engineering-wiki">
   Data Preprocessing and Feature Engineering Wiki
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-transformation-wiki">
     Data Transformation Wiki
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#feature-scaling-wiki">
       Feature Scaling Wiki
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#normality-testing-wiki">
   Normality Testing Wiki
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ml-machine-learning-framework">
   ML Machine Learning Framework
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-overfitting">
     Model Overfitting
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regression-wiki">
   Regression Wiki
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linear-regression">
     Linear Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#let-textbf-x-n-times-p-1-be-the-n-times-p-1-matrix-with-each-row-an-input-vector-br-textbf-x">
   Let
   <span class="math notranslate nohighlight">
    \(\textbf{X}_{[N \times (p + 1)]}\)
   </span>
   be the
   <span class="math notranslate nohighlight">
    \(N \times (p + 1)\)
   </span>
   matrix with each row an input vector
   <br/>
   $$
\textbf{X}
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#begin-bmatrix-x-1-x-p-1-end-bmatrix">
   \begin{bmatrix}
X_1 &amp; … &amp; X_{p + 1} \
\end{bmatrix}
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generalized-linear-models-wiki">
     Generalized Linear Models Wiki
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#supervised-ml-classification">
   Supervised ML: Classification
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classifiers">
     Classifiers
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#decision-tree">
     Decision Tree
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-regression">
     Logistic Regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#knn-k-nearest-neighbors-classifier">
     KNN K-Nearest Neighbors Classifier
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#svm-support-vector-machine">
     SVM Support Vector Machine
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ensembling">
     Ensembling
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#binary-classification-performance-evaluation-wiki">
     Binary Classification Performance Evaluation Wiki
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#evaluation-measures">
       Evaluation Measures
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multiclass-classification-performance-evaluation">
     Multiclass Classification Performance Evaluation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       Evaluation Measures
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bayesian-classification">
       Bayesian Classification
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#naive-bayes-classifier">
       Naive Bayes Classifier
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#statistics">
   Statistics
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#frequency-distribution-vs-relative-frequency-distribution">
     Frequency Distribution vs Relative Frequency Distribution
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#clt-central-limit-theorem">
     CLT Central Limit Theorem
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#standard-deviation">
     Standard Deviation
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#standardized-z-score">
     Standardized z-Score
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ppmcc-pearson-s-product-moment-correlation-coefficient">
     PPMCC Pearson’s Product-Moment Correlation Coefficient
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regression-analysis-and-the-estimation-of-a-regression-equation">
     Regression Analysis and the Estimation of a Regression Equation
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gaussian-distribution">
     Gaussian Distribution
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#empirical-rule-for-normally-distributed-data">
       Empirical Rule for normally-distributed data
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#standard-normal-distribution">
     Standard Normal Distribution
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probability-theory">
   Probability Theory
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stochastic-processes-and-time-series">
   Stochastic Processes and Time Series
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random-walk">
     Random Walk
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#arima-0-1-0">
   ARIMA(0, 1, 0)
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#arima-0-0-1">
   ARIMA(0, 0, 1)
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sma-k-simple-moving-average-wiki-br-dataset-x-1-x-n-br-window-k-br-text-sma-k">
   <strong>
    SMA
    <span class="math notranslate nohighlight">
     \(_k\)
    </span>
    Simple Moving Average
   </strong>
   Wiki
   <br/>
   dataset
   <span class="math notranslate nohighlight">
    \(= \{x_1, ..., x_n\}\)
   </span>
   <br/>
   window
   <span class="math notranslate nohighlight">
    \(k\)
   </span>
   <br/>
   $$
\text{SMA}_k
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#frac-x-n-k-1-x-n-k-2-x-n-k">
   \frac{x_{n - k + 1} + x_{n - k + 2} + … + x_n}{k}
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dsp-digital-signal-processing-and-filters">
   DSP Digital Signal Processing and Filters
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mathematical-finance">
   Mathematical Finance
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tvm-time-value-of-money">
     TVM Time Value of Money
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mathematical-functions">
   Mathematical Functions
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ramp-function-wiki-br-r-x-begin-cases-x-x-ge-0-0-x-lt-0-end-cases">
   <strong>
    Ramp Function
   </strong>
   Wiki
   <br/>
   $$
R(x)=
\begin{cases}
x &amp; x \ge 0 \
0 &amp; x \lt 0 \
\end{cases}
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resources">
   Resources
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="imports">
<h1>Imports<a class="headerlink" href="#imports" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline

<span class="c1">####################</span>

<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">datetime</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># suppress scientific notation in NumPy output</span>
  <span class="c1"># see the following discussion for more information</span>
  <span class="c1"># https://stackoverflow.com/questions/9777783/suppress-scientific-notation-in-numpy-when-creating-array-from-nested-list</span>
<span class="kn">import</span> <span class="nn">numpy.random</span> <span class="k">as</span> <span class="nn">npr</span>
<span class="kn">import</span> <span class="nn">numpy_financial</span> <span class="k">as</span> <span class="nn">npf</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">pylab</span> <span class="kn">import</span> <span class="n">mpl</span><span class="p">,</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn&#39;</span><span class="p">)</span>
<span class="c1">#plt.style.available # display available styles</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">scipy.spatial.distance</span> <span class="kn">import</span> <span class="n">pdist</span><span class="p">,</span> <span class="n">squareform</span>
  <span class="c1"># squareform(pdist(ndarray, metric=&#39;minkowski&#39;, p=2))</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">scs</span>
<span class="kn">import</span> <span class="nn">scipy.optimize</span> <span class="k">as</span> <span class="nn">sco</span>
<span class="kn">import</span> <span class="nn">scipy.interpolate</span> <span class="k">as</span> <span class="nn">sci</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">signal</span> <span class="c1"># signal processing</span>
  <span class="c1"># https://www.gaussianwaves.com/2010/11/moving-average-filter-ma-filter-2/</span>

<span class="c1">####################</span>

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span><span class="p">,</span> <span class="n">minmax_scale</span><span class="p">,</span> <span class="n">StandardScaler</span>

<span class="c1"># Decision Tree Classifier [sklearn]</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">import</span> <span class="nn">pydotplus</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="c1"># Linear Classifiers [sklearn]</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">LogisticRegression</span>

<span class="c1"># SVM [sklearn]</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>

<span class="c1"># KNN Classifier [sklearn]</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="c1"># Ensembling [sklearn]</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">ensemble</span>

<span class="c1"># Performance Evaluation</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">r2_score</span>

<span class="c1">####################</span>

<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
  <span class="c1"># Hodrick-Prescott Filter: decomposes a time series into shorter-term fluctuations and longer-term trends</span>
  <span class="c1">#   ts_noise, ts_trend = sm.tsa.filters.hpfilter(df)</span>
  <span class="c1">#   ts_noise.plot();</span>
  <span class="c1">#   ts_trend.plot();</span>
<span class="kn">from</span> <span class="nn">statsmodels.tsa.seasonal</span> <span class="kn">import</span> <span class="n">seasonal_decompose</span>
  <span class="c1"># time series decomposition: seasonal_decompose(df, model=&#39;multiplicative&#39;).plot();</span>
<span class="kn">from</span> <span class="nn">statsmodels.graphics.tsaplots</span> <span class="kn">import</span> <span class="n">plot_acf</span><span class="p">,</span> <span class="n">plot_pacf</span>
  <span class="c1"># Autocorrelation and Partial Autocorrelation</span>
<span class="kn">from</span> <span class="nn">statsmodels.tsa.stattools</span> <span class="kn">import</span> <span class="n">adfuller</span>
  <span class="c1"># Augmented Dickey-Fuller statistical test for stationarity (p-value &lt; 0.05 is stationary)</span>
    
<span class="kn">from</span> <span class="nn">statsmodels.tsa.ar_model</span> <span class="kn">import</span> <span class="n">AutoReg</span><span class="p">,</span> <span class="n">ar_select_order</span>
<span class="kn">from</span> <span class="nn">statsmodels.tsa.api</span> <span class="kn">import</span> <span class="n">acf</span><span class="p">,</span> <span class="n">pacf</span><span class="p">,</span> <span class="n">graphics</span>

<span class="kn">from</span> <span class="nn">statsmodels.tsa.arima_model</span> <span class="kn">import</span> <span class="n">ARMA</span><span class="p">,</span> <span class="n">ARIMA</span>
  <span class="c1"># model_arma = ARMA(df, order=(1, 1))</span>
  <span class="c1"># model_arima = ARIMA(df, order=(1, 1, 1))</span>
  <span class="c1"># results = model.fit()</span>
  <span class="c1"># results.summary()</span>
<span class="kn">from</span> <span class="nn">statsmodels.tsa.arima.model</span> <span class="kn">import</span> <span class="n">ARIMA</span>

<span class="kn">from</span> <span class="nn">arch</span> <span class="kn">import</span> <span class="n">arch_model</span>

<span class="c1">####################</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<hr class="docutils" />
</div>
<hr class="docutils" />
<div class="section" id="table-of-contents">
<h1>Table of Contents<a class="headerlink" href="#table-of-contents" title="Permalink to this headline">¶</a></h1>
<ol class="simple">
<li><p>Data</p></li>
<li><p>Data I/O</p></li>
<li><p>Descriptive Data Analysis and Summary Statistics</p></li>
<li><p>Data Preprocessing and Feature Engineering</p></li>
<li><p>Normality Testing</p></li>
<li><p>ML Machine Learning Framework</p></li>
<li><p>Regression</p></li>
<li><p>Supervised ML: Classification</p>
<ul class="simple">
<li><p>Binary Classification Performance Evaluation</p></li>
<li><p>Multiclass Classification Performance Evaluation</p></li>
</ul>
</li>
<li><p>Statistics</p></li>
<li><p>Probability Theory</p></li>
<li><p>Stochastic Processes and Time Series</p></li>
<li><p>DSP Digital Signal Processing and Filters</p></li>
<li><p>Mathematical Finance</p></li>
<li><p>Mathematical Functions</p></li>
<li><p>Resources</p></li>
</ol>
<hr class="docutils" />
<hr class="docutils" />
</div>
<hr class="docutils" />
<div class="section" id="data-wiki">
<h1>Data <a class="reference external" href="https://en.wikipedia.org/wiki/Data">Wiki</a><a class="headerlink" href="#data-wiki" title="Permalink to this headline">¶</a></h1>
<hr class="docutils" />
<p>Data Object<br>
Data Attribute<br>
    
Quantitative Attribute<br>
        
Continuous Attribute<br>
    
Qualitative Attribute<br></p>
<p>Data Type<br>
Data Quality<br></p>
<ul class="simple">
<li><p>noise</p></li>
<li><p>outliers</p></li>
<li><p>missing data</p></li>
<li><p>inconsistent data</p></li>
<li><p>duplicate data</p></li>
<li><p>bias</p></li>
<li><p>unrepresentative data</p></li>
</ul>
<p>Structured Data<br>
Semi Structured Data<br>
Unstructured Data<br></p>
<hr class="docutils" />
<hr class="docutils" />
</div>
<hr class="docutils" />
<div class="section" id="data-i-o">
<h1>Data I/O<a class="headerlink" href="#data-i-o" title="Permalink to this headline">¶</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">np.load('.npy')</span></code><br>
<code class="docutils literal notranslate"><span class="pre">np.loadtxt('.csv',</span> <span class="pre">delimiter=',')</span></code><br></p>
<p><code class="docutils literal notranslate"><span class="pre">pd.read_csv('.csv',</span> <span class="pre">index_col=0,</span> <span class="pre">parse_dates=True,</span> <span class="pre">infer_datetime_format=True)</span></code><br></p>
<p><code class="docutils literal notranslate"><span class="pre">with</span> <span class="pre">open('.csv',</span> <span class="pre">'r')</span> <span class="pre">as</span> <span class="pre">input_file:</span></code><br></p>
<hr class="docutils" />
<hr class="docutils" />
</div>
<hr class="docutils" />
<div class="section" id="descriptive-data-analysis-and-summary-statistics">
<h1>Descriptive Data Analysis and Summary Statistics<a class="headerlink" href="#descriptive-data-analysis-and-summary-statistics" title="Permalink to this headline">¶</a></h1>
<hr class="docutils" />
<p><strong>Dataset</strong> <span class="math notranslate nohighlight">\(X\)</span> <a class="reference external" href="https://en.wikipedia.org/wiki/Data_set">Wiki</a><br>
$<span class="math notranslate nohighlight">\(X = \{ x_1, x_2, ..., x_n \}\)</span><span class="math notranslate nohighlight">\(
where \)</span>x_i<span class="math notranslate nohighlight">\( for \)</span>i = 1, 2, …, n$ are data objects, data points, data instances, etc. <a class="reference external" href="https://en.wikipedia.org/wiki/Data">Wiki</a><br></p>
<p><strong>Dataset Size or Count</strong> <span class="math notranslate nohighlight">\(n\)</span><br></p>
<p><strong>Maximum</strong> max<br>
$<span class="math notranslate nohighlight">\(\text{max} = x_i \in X \,\text{s.t.}\, x_i \ge x_j \,\,\,\forall x_j \in X, j \ne i\)</span>$</p>
<p><strong>Minimum</strong> min<br>
$<span class="math notranslate nohighlight">\(\text{min} = x_i \in X \,\text{s.t.}\, x_i \le x_j \,\,\,\forall x_j \in X, j \ne i\)</span>$</p>
<p><strong>Outlier</strong><br>
<span class="math notranslate nohighlight">\(x_i \in \{x_i \)</span> s.t. <span class="math notranslate nohighlight">\( x_i \lt \text{Q}_1 - 1.5\times\text{IQR} \)</span> or <span class="math notranslate nohighlight">\( x_i \gt \text{Q}_3 + 1.5\times\text{IQR}\}\)</span></p>
<p><strong>k-th Quantile</strong>
<span class="math notranslate nohighlight">\(x_i\)</span> s.t. <span class="math notranslate nohighlight">\(\left(\frac{100}{q}k\right)\)</span>% of the data values are <span class="math notranslate nohighlight">\(\leq x_i\)</span> and <span class="math notranslate nohighlight">\((100 - \frac{100}{q}k)\)</span>% of the data values are <span class="math notranslate nohighlight">\(\geq x_i\)</span> where <span class="math notranslate nohighlight">\(0 \leq k \leq q\)</span> <br></p>
<p><strong>k-th Percentile</strong>
<span class="math notranslate nohighlight">\(x_i\)</span> s.t. <span class="math notranslate nohighlight">\(k\)</span>% of the data values are <span class="math notranslate nohighlight">\(\leq x_i\)</span> and <span class="math notranslate nohighlight">\((100 - k)\)</span>% of the data values are <span class="math notranslate nohighlight">\(\geq x_i\)</span> where <span class="math notranslate nohighlight">\(0 \leq k \leq 100\)</span> <br></p>
<p><strong>k-th Quartile</strong>
<span class="math notranslate nohighlight">\(x_i\)</span> s.t. <span class="math notranslate nohighlight">\((25k)\)</span>% of the data values are <span class="math notranslate nohighlight">\(\leq x_i\)</span> and <span class="math notranslate nohighlight">\((100 - 25k)\)</span>% of the data values are <span class="math notranslate nohighlight">\(\geq x_i\)</span> where <span class="math notranslate nohighlight">\(0 \leq k \leq 4\)</span> <br></p>
<hr class="docutils" />
<div class="section" id="measures-of-central-tendency-wiki-or-averages-wiki">
<h2>Measures of Central Tendency <a class="reference external" href="https://en.wikipedia.org/wiki/Central_tendency">Wiki</a> or Averages <a class="reference external" href="https://en.wikipedia.org/wiki/Average">Wiki</a><a class="headerlink" href="#measures-of-central-tendency-wiki-or-averages-wiki" title="Permalink to this headline">¶</a></h2>
<div class="section" id="pythagorean-means-wiki">
<h3>Pythagorean Means <a class="reference external" href="https://en.wikipedia.org/wiki/Pythagorean_means">Wiki</a><a class="headerlink" href="#pythagorean-means-wiki" title="Permalink to this headline">¶</a></h3>
<p><strong>Arithmetic Mean</strong> <span class="math notranslate nohighlight">\(\mu_a\)</span> <a class="reference external" href="https://en.wikipedia.org/wiki/Arithmetic_mean">Wiki</a><br>
$<span class="math notranslate nohighlight">\(
\begin{align}
\mu_a
&amp;= \frac{\sum_{i = 1}^n x_i}{n} \\
&amp;= \frac{x_1 + x_2 + ... + x_n}{n} \\
\end{align}
\)</span>$</p>
<p>Population Mean <span class="math notranslate nohighlight">\(\mu\)</span> <br>
Sample Mean <span class="math notranslate nohighlight">\(\bar{x} = \frac{\sum x_i}{n}\)</span> <br></p>
<p><strong>Geometric Mean</strong> <span class="math notranslate nohighlight">\(\mu_g\)</span> <a class="reference external" href="https://en.wikipedia.org/wiki/Geometric_mean">Wiki</a><br>
the <span class="math notranslate nohighlight">\(n\)</span>th root of the product of <span class="math notranslate nohighlight">\(n\)</span> numbers<br>
$<span class="math notranslate nohighlight">\(
\begin{align}
\mu_g
&amp;= \left( \prod_{i = 1}^n x_i \right)^{\frac{1}{n}} \\
&amp;= \sqrt[n]{x_1x_2...x_n} \\
\end{align}
\)</span>$</p>
<p><strong>Harmonic Mean</strong> <span class="math notranslate nohighlight">\(\mu_h\)</span> <a class="reference external" href="https://en.wikipedia.org/wiki/Harmonic_mean">Wiki</a><br>
“the reciprocal of the arithmetic mean of the reciprocals”<br>
$<span class="math notranslate nohighlight">\(
\begin{align}
\mu_h
&amp;= \left( \frac{\sum_{i = 1}^n x_i^{-1}}{n} \right)^{-1} = \frac{n}{\sum_{i = 1}^n \frac{1}{x_i}} \\
&amp;= \frac{n}{\frac{1}{x_1} + \frac{1}{x_2} + ... + \frac{1}{x_n}} \\
\end{align}
\)</span>$</p>
<p><strong>Median (50th Percentile)</strong> <span class="math notranslate nohighlight">\(M\)</span><br>
    
If <span class="math notranslate nohighlight">\(n\)</span> is odd, then <span class="math notranslate nohighlight">\(M = x_i\)</span> s.t. <span class="math notranslate nohighlight">\(x_i\)</span> is the <span class="math notranslate nohighlight">\(\frac{(n + 1)}{2}\)</span>-th element <br>
    
If <span class="math notranslate nohighlight">\(n\)</span> is even, then <span class="math notranslate nohighlight">\(M\)</span> is the average of the <span class="math notranslate nohighlight">\(\frac{n}{2}\)</span>-th and <span class="math notranslate nohighlight">\(\frac{n}{2} + 1\)</span>-th elements <br></p>
<p><strong>Mode</strong><br></p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="measures-of-dispersion-wiki">
<h2>Measures of Dispersion <a class="reference external" href="https://en.wikipedia.org/wiki/Statistical_dispersion">Wiki</a><a class="headerlink" href="#measures-of-dispersion-wiki" title="Permalink to this headline">¶</a></h2>
<p><strong>Range</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/Range_(statistics)">Wiki</a><br>
$<span class="math notranslate nohighlight">\(\text{Range} = \text{maximum} - \text{minimum}\)</span>$</p>
<p><strong>Interquartile Range</strong> IQR <a class="reference external" href="https://en.wikipedia.org/wiki/Interquartile_range">Wiki</a><br>
$<span class="math notranslate nohighlight">\(\text{IQR} = \text{Q}_3 - \text{Q}_1 \,\,\,\text{where Q}_1 \text{is the Lower Quartile (25th Percentile) and Q}_3 \text{is the Upper Quartile (75th Percentile)}\)</span>$</p>
<p><strong>Standard Deviation</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/Standard_deviation">Wiki</a><br>
Population Standard Deviation <span class="math notranslate nohighlight">\(\sigma = \sqrt{\frac{\sum(x_i - \mu)^2}{n}}\)</span> <br>
Sample Standard Deviation <span class="math notranslate nohighlight">\(s = \sqrt{\frac{\sum(x_i - \bar{x})^2}{n - 1}}\)</span> <br>
    
Step 1. Calculate the sample mean. <br>
    
Step 2. For each observation, calculate the difference between the data value and the mean. <br>
    
Step 3. Square each difference calculated in step 2. <br>
    
Step 4. Sum the squared differences calculated in step 3, and then divide this sum by n - 1. <br>
    
Step 5. Take the square root of the variance calculated in step 4. <br>
    
For normally distributed <span class="math notranslate nohighlight">\(n \geq 200\)</span>, <span class="math notranslate nohighlight">\(s \approx \frac{\text{Range}}{6}\)</span><br></p>
<p><strong>Variance</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/Variance">Wiki</a><br>
Population Variance <span class="math notranslate nohighlight">\(\sigma^2\)</span> <br>
Sample Variance <span class="math notranslate nohighlight">\(s^2 = \frac{\sum(x_i - \bar{x})^2}{n - 1}\)</span> <br></p>
<p><strong>Mean Absolute Difference</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/Mean_absolute_difference">Wiki</a><br></p>
<p><strong>Mean Absolute Deviation</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/Average_absolute_deviation">Wiki</a><br></p>
<p><strong>Median Absolute Deviation</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/Median_absolute_deviation">Wiki</a><br></p>
<hr class="docutils" />
<p>Pearson’s Product-Moment Correlation Coefficient <span class="math notranslate nohighlight">\(r = \frac{1}{n - 1} \sum_i \left(\frac{x_i - \bar{x}}{s_x}\right)\left(\frac{y_i - \bar{y}}{s_y}\right)\)</span> where <span class="math notranslate nohighlight">\(-1 \leq r \leq 1\)</span> <br>
Squared Correlation <span class="math notranslate nohighlight">\(r^2\)</span> where <span class="math notranslate nohighlight">\(0 \leq r^2 \leq 1\)</span> <br></p>
<p>Covariance <br></p>
<p>Skewness <a class="reference external" href="https://en.wikipedia.org/wiki/Skewness">Wiki</a><br>
Kurtosis <a class="reference external" href="https://en.wikipedia.org/wiki/Kurtosis">Wiki</a><br>
Odds <a class="reference external" href="https://en.wikipedia.org/wiki/Odds">Wiki</a><br>
Odds Ratio <a class="reference external" href="https://en.wikipedia.org/wiki/Odds_ratio">Wiki</a><br></p>
</div>
<hr class="docutils" />
<div class="section" id="proximity-measures-similarity-and-dissimilarity">
<h2>Proximity Measures (Similarity and Dissimilarity)<a class="headerlink" href="#proximity-measures-similarity-and-dissimilarity" title="Permalink to this headline">¶</a></h2>
<p>proximity measures are used in clustering, nearest-neighbors classification, and anomaly detection<br>
usually, the intial dataset is not needed once proximities are computed<br>
the initial dataset is transformed to a proximity space prior to data analysis<br></p>
<p>Proximity Measures between objects with a single attribute<br>
Proximity Measures between objects with more than one attribute<br>
    
Jaccard Similarity<br>
    
Cosine Similarity<br>
    
Kernel Methods<br>
    
Distance Measures and Metrics<br>
Proximity Measures between Attributes<br>
    
Correlation<br>
    
MI Mutual Information<br></p>
<p><strong>Proximity (Similarity and Dissimilarity)</strong><br>
the proximity between two data objects is a function of the proximity between the corresponding attributes of the two objects<br></p>
<p><strong>Similarity</strong> between two data objects is a numerical measure of the degree to which the two objects are alike<br>
usually <span class="math notranslate nohighlight">\(\in [0, 1]\)</span> where <span class="math notranslate nohighlight">\(0\)</span> is no similarity between pairs of objects and <span class="math notranslate nohighlight">\(1\)</span> is complete similarity between pairs of objects<br></p>
<p><strong>Dissimilarity</strong> between two data objects is a numerical measure of the degree to which the two objects are not alike<br>
sometimes <span class="math notranslate nohighlight">\(\in [0, 1]\)</span><br>
sometimes <span class="math notranslate nohighlight">\(\in [0, \infty]\)</span><br></p>
<hr class="docutils" />
<div class="section" id="jaccard-proximity-measure">
<h3>Jaccard Proximity Measure<a class="headerlink" href="#jaccard-proximity-measure" title="Permalink to this headline">¶</a></h3>
<p>useful for sparse data such as documents<br></p>
</div>
<hr class="docutils" />
<div class="section" id="cosine-proximity-measure">
<h3>Cosine Proximity Measure<a class="headerlink" href="#cosine-proximity-measure" title="Permalink to this headline">¶</a></h3>
<p>useful for sparse data such as documents<br></p>
</div>
<hr class="docutils" />
<div class="section" id="distance-measures-and-metrics">
<h3>Distance Measures and Metrics<a class="headerlink" href="#distance-measures-and-metrics" title="Permalink to this headline">¶</a></h3>
<p>distance measures specify different ways of combining the differences in each dimension/attribute into an overall distance<br>
useful for non-sparse data such as time series and multi-dimensional points<br></p>
<p><strong>Minkowski Distance</strong> <span class="math notranslate nohighlight">\(d\)</span> between two points <span class="math notranslate nohighlight">\(\textbf{x} = (x_1, x_2, ..., x_n)\)</span> and <span class="math notranslate nohighlight">\(\textbf{y} = (y_1, y_2, ..., y_n)\)</span><br>
$<span class="math notranslate nohighlight">\(d(\textbf{x}, \textbf{y}) = \left( \sum_{k = 1}^n |x_k - y_k|^r \right)^{\frac{1}{r}}\)</span>$</p>
<p><strong>Manhattan Distance (<span class="math notranslate nohighlight">\(L_1\)</span> Norm)</strong> <span class="math notranslate nohighlight">\(d\)</span> between two points <span class="math notranslate nohighlight">\(\textbf{x} = (x_1, x_2, ..., x_n)\)</span> and <span class="math notranslate nohighlight">\(\textbf{y} = (y_1, y_2, ..., y_n)\)</span><br>
Minkowski <span class="math notranslate nohighlight">\(r = 1\)</span><br>
$<span class="math notranslate nohighlight">\(d(\textbf{x}, \textbf{y}) = \sum_{k = 1}^n |x_k - y_k|\)</span>$</p>
<p><strong>Hamming Distance</strong> is the Manhattan distance between binary vectors where <span class="math notranslate nohighlight">\(x_k, y_k \in \{0, 1\}\)</span><br></p>
<p><strong>Euclidean Distance (<span class="math notranslate nohighlight">\(L_2\)</span> Norm)</strong> <span class="math notranslate nohighlight">\(d\)</span> between two points <span class="math notranslate nohighlight">\(\textbf{x} = (x_1, x_2, ..., x_n)\)</span> and <span class="math notranslate nohighlight">\(\textbf{y} = (y_1, y_2, ..., y_n)\)</span><br>
Minkowski <span class="math notranslate nohighlight">\(r = 2\)</span><br>
$<span class="math notranslate nohighlight">\(d(\textbf{x}, \textbf{y}) = \sqrt{\sum_{k = 1}^n (x_k - y_k)^2}\)</span>$</p>
<p><strong>Supremum Distance (<span class="math notranslate nohighlight">\(L_{\infty}\)</span> Norm)</strong> <span class="math notranslate nohighlight">\(d\)</span> between two points <span class="math notranslate nohighlight">\(\textbf{x} = (x_1, x_2, ..., x_n)\)</span> and <span class="math notranslate nohighlight">\(\textbf{y} = (y_1, y_2, ..., y_n)\)</span><br>
the maximum difference between any attribute of the objects<br>
$<span class="math notranslate nohighlight">\(d(\textbf{x}, \textbf{y}) = \lim_{r \rightarrow \infty} \left( \sum_{k = 1}^n |x_k - y_k|^r \right)^{\frac{1}{r}}\)</span>$</p>
<p><strong>Correlation Distance</strong><br></p>
<hr class="docutils" />
<p>distance measures in scipy</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_42_0.png" src="../_images/mathematical_foundations_42_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># manhattan distance matrix</span>
<span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">squareform</span><span class="p">(</span><span class="n">pdist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;cityblock&#39;</span><span class="p">)),</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0., 4., 4., 6.],
       [4., 0., 2., 4.],
       [4., 2., 0., 2.],
       [6., 4., 2., 0.]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># euclidean distance matrix</span>
<span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">squareform</span><span class="p">(</span><span class="n">pdist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)),</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.   , 2.828, 3.162, 5.099],
       [2.828, 0.   , 1.414, 3.162],
       [3.162, 1.414, 0.   , 2.   ],
       [5.099, 3.162, 2.   , 0.   ]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># supremum distance matrix</span>
<span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">squareform</span><span class="p">(</span><span class="n">pdist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;minkowski&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)),</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0., 2., 3., 5.],
       [2., 0., 1., 3.],
       [3., 1., 0., 2.],
       [5., 3., 2., 0.]])
</pre></div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="mi-mutual-information">
<h3>MI Mutual Information<a class="headerlink" href="#mi-mutual-information" title="Permalink to this headline">¶</a></h3>
<p>useful for different kinds of data and for detecting nonlinear relationships<br></p>
<hr class="docutils" />
<hr class="docutils" />
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="data-preprocessing-and-feature-engineering-wiki">
<h1>Data Preprocessing and Feature Engineering <a class="reference external" href="https://en.wikipedia.org/wiki/Feature_engineering">Wiki</a><a class="headerlink" href="#data-preprocessing-and-feature-engineering-wiki" title="Permalink to this headline">¶</a></h1>
<p><strong>Binarization</strong><br></p>
<p><strong>Dimensionality Reduction</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/Dimensionality_reduction">Wiki</a><br></p>
<p><strong>Discretization</strong><br></p>
<p><strong>Dummification</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/Dummy_variable_(statistics)">Wiki</a><br></p>
<p><strong>Encoding</strong><br>
One Hot Encoding <a class="reference external" href="https://en.wikipedia.org/wiki/One-hot">Wiki</a><br></p>
<p><strong>Feature Subset Selection</strong><br></p>
<p>Centering Matrix <a class="reference external" href="https://en.wikipedia.org/wiki/Centering_matrix">Wiki</a><br>
Normalization <a class="reference external" href="https://en.wikipedia.org/wiki/Normalization_(statistics)">Wiki</a><br></p>
<hr class="docutils" />
<div class="section" id="data-transformation-wiki">
<h2>Data Transformation <a class="reference external" href="https://en.wikipedia.org/wiki/Data_transformation_(statistics)">Wiki</a><a class="headerlink" href="#data-transformation-wiki" title="Permalink to this headline">¶</a></h2>
<p>linear transformations preserve the relative distance between data points while changing their location and/or dispersion<br></p>
<div class="section" id="feature-scaling-wiki">
<h3>Feature Scaling <a class="reference external" href="https://en.wikipedia.org/wiki/Feature_scaling">Wiki</a><a class="headerlink" href="#feature-scaling-wiki" title="Permalink to this headline">¶</a></h3>
<p><strong><span class="math notranslate nohighlight">\([a, b]\)</span> Scaling (Min-Max Normalization)</strong><br>
$<span class="math notranslate nohighlight">\(
\begin{align}
x' &amp;= a + \frac{(x - x_{\text{min}})(b - a)}{x_\text{max} - x_\text{min}} &amp; \text{where}\, x \,\text{is the original value and}\, x' \,\text{is the normalized value} \\
\end{align}
\)</span>$</p>
<p><strong>Mean Normalization</strong><br>
$<span class="math notranslate nohighlight">\(
\begin{align}
x' &amp;= \frac{x - \bar{x}}{x_\text{max} - x_\text{min}} &amp; \text{where}\, x \,\text{is the original value and}\, x' \,\text{is the normalized value} \\
\end{align}
\)</span>$</p>
<p><strong>Standardization (z-Score Normalization)</strong><br>
Standardized z-Score <span class="math notranslate nohighlight">\(z = \frac{x_i - \bar{x}}{s}\)</span>
$<span class="math notranslate nohighlight">\(
\begin{align}
x' &amp;= \frac{x - \bar{x}}{\sigma} &amp; \text{where}\, x \,\text{is the original value and}\, x' \,\text{is the normalized value} \\
\end{align}
\)</span>$</p>
<p><strong>Zero Centering</strong><br>
Suppose you have a dataset <span class="math notranslate nohighlight">\(X_{\text{not zero-centered}}\)</span> whose arithmetic mean is <span class="math notranslate nohighlight">\(\bar{X}_{\text{not zero-centered}} \ne 0\)</span><br>
The zero-centered dataset is given by <span class="math notranslate nohighlight">\(X_{\text{zero-centered}} = X_{\text{not zero-centered}} - \bar{X}_{\text{not zero-centered}}\)</span><br>
<span class="math notranslate nohighlight">\(\bar{X}_{\text{zero-centered}} = 0\)</span><br></p>
<hr class="docutils" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># original data</span>
<span class="n">npr</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e3</span><span class="p">),</span> <span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
<span class="c1">#plt.hist(data, bins=100);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_59_0.png" src="../_images/mathematical_foundations_59_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># zero-centered data</span>
<span class="n">npr</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e3</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
<span class="c1">#plt.hist(data, bins=100);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_60_0.png" src="../_images/mathematical_foundations_60_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># [0, 1]-scaled data</span>
<span class="n">npr</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e3</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">min</span><span class="p">())</span><span class="o">/</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="n">display</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">data</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
<span class="c1">#plt.hist(data, bins=100);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0
</pre></div>
</div>
<img alt="../_images/mathematical_foundations_61_2.png" src="../_images/mathematical_foundations_61_2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># normalized data (zero-centered, unit-scaled)</span>
<span class="n">npr</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e3</span><span class="p">))</span>
<span class="n">display</span><span class="p">(</span>
    <span class="n">data</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span>
    <span class="n">data</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span>
    <span class="n">data</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
    <span class="n">data</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
    <span class="n">data</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="o">/</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="n">display</span><span class="p">(</span>
    <span class="n">data</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span>
    <span class="n">data</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span>
    <span class="n">data</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
<span class="c1">#plt.hist(data, bins=100);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>15.518710228043165
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.9077138904001467
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5.609223643023556
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-6.001772694619462
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>11.61099633764302
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.483095806760215
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.5169041932397849
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9999999999999999
</pre></div>
</div>
<img alt="../_images/mathematical_foundations_62_8.png" src="../_images/mathematical_foundations_62_8.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># standardized data</span>
<span class="n">npr</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e3</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="o">/</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
<span class="c1">#plt.hist(data, bins=100);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_63_0.png" src="../_images/mathematical_foundations_63_0.png" />
</div>
</div>
<hr class="docutils" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">npr</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e3</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">minmax_scale</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_65_0.png" src="../_images/mathematical_foundations_65_0.png" />
</div>
</div>
<hr class="docutils" />
<hr class="docutils" />
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="normality-testing-wiki">
<h1>Normality Testing <a class="reference external" href="https://en.wikipedia.org/wiki/Normality_test">Wiki</a><a class="headerlink" href="#normality-testing-wiki" title="Permalink to this headline">¶</a></h1>
<hr class="docutils" />
<hr class="docutils" />
</div>
<hr class="docutils" />
<div class="section" id="ml-machine-learning-framework">
<h1>ML Machine Learning Framework<a class="headerlink" href="#ml-machine-learning-framework" title="Permalink to this headline">¶</a></h1>
<p>A <strong>machine learning algorithm</strong> is an algorithm that is capable of improving a computer program’s performance at some task via experience<br></p>
<hr class="docutils" />
<div class="section" id="model-overfitting">
<h2>Model Overfitting<a class="headerlink" href="#model-overfitting" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">1500</span>
<span class="n">mean1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">14</span><span class="p">]</span>  <span class="c1"># center of first Gaussian distribution</span>
<span class="n">mean2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>  <span class="c1"># center of second Gaussian distribution</span>
<span class="n">mean3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">]</span> <span class="c1"># center of third Gaussian distribution</span>
<span class="n">cov</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">3.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">]]</span> <span class="c1"># diagonal covariance</span>
<span class="n">npr</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">6</span><span class="p">))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">npr</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean2</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">6</span><span class="p">))))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">npr</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean3</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">6</span><span class="p">))))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="mi">20</span><span class="o">*</span><span class="n">npr</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">))))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;r.&#39;</span><span class="p">,</span> <span class="n">X</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">):,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">):,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k.&#39;</span><span class="p">,</span> <span class="n">ms</span><span class="o">=</span><span class="mi">4</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_73_0.png" src="../_images/mathematical_foundations_73_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(300, 2)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1200, 2)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(300,)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1200,)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">maxdepths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">50</span><span class="p">]</span>

<span class="n">trainAcc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">maxdepths</span><span class="p">))</span>
<span class="n">testAcc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">maxdepths</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">depth</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">maxdepths</span><span class="p">):</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">depth</span><span class="p">)</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
    <span class="n">Y_predTrain</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">Y_predTest</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">trainAcc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_predTrain</span><span class="p">)</span>
    <span class="n">testAcc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">Y_predTest</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">maxdepths</span><span class="p">,</span> <span class="n">trainAcc</span><span class="p">,</span> <span class="s1">&#39;ro-&#39;</span><span class="p">,</span> <span class="n">maxdepths</span><span class="p">,</span> <span class="n">testAcc</span><span class="p">,</span> <span class="s1">&#39;bv--&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Training Accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;Test Accuracy&#39;</span><span class="p">]);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Max depth&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_75_0.png" src="../_images/mathematical_foundations_75_0.png" />
</div>
</div>
<hr class="docutils" />
<hr class="docutils" />
</div>
</div>
<hr class="docutils" />
<div class="section" id="regression-wiki">
<h1>Regression <a class="reference external" href="https://en.wikipedia.org/wiki/Regression_analysis">Wiki</a><a class="headerlink" href="#regression-wiki" title="Permalink to this headline">¶</a></h1>
<hr class="docutils" />
<div class="section" id="linear-regression">
<h2>Linear Regression<a class="headerlink" href="#linear-regression" title="Permalink to this headline">¶</a></h2>
<p>given: input vector <span class="math notranslate nohighlight">\(X^T = (X_1, ..., X_p) \in \mathbb{R}^p\)</span><br>
objective: predict a real-valued output <span class="math notranslate nohighlight">\(Y \in \mathbb{R}\)</span><br>
output: a linear function of the input<br></p>
<p><strong>Linear Regression Model</strong><br>
$<span class="math notranslate nohighlight">\(
\begin{align}
f(X)
&amp; = \beta_0 + \sum_{j = 1}^p X_j \beta_j \\
&amp; = \beta_0 + X_1 \beta_1 + ... + X_j \beta_j \\
\end{align}
\)</span>$</p>
<p>assumption: the regression function <span class="math notranslate nohighlight">\(\text{E}(Y|X)\)</span> is linear or the linear model is a reasonable approximation<br></p>
<p>the variables <span class="math notranslate nohighlight">\(X_j\)</span> can come from different sources:<br></p>
<ol class="simple">
<li><p>quantitative inputs</p></li>
<li><p>transformations of quantitative inputs, such as log, square-root, or square</p></li>
<li><p>basis expansions, such as <span class="math notranslate nohighlight">\(X_2 = X_1^2\)</span>, <span class="math notranslate nohighlight">\(X_3 = X_1^3\)</span>, leading to a polynomial representation</p></li>
<li><p>numeric or “dummy” coding of the levels of qualitative inputs. For example, if <span class="math notranslate nohighlight">\(G\)</span> is a five-level factor input, we might create <span class="math notranslate nohighlight">\(X_j\)</span>, <span class="math notranslate nohighlight">\(j = 1, ..., 5\)</span>, such that <span class="math notranslate nohighlight">\(X_j = I(G = j)\)</span>. Together this group of <span class="math notranslate nohighlight">\(X_j\)</span> represents the effect of <span class="math notranslate nohighlight">\(G\)</span> by a set of level-dependent constants, since in <span class="math notranslate nohighlight">\(\sum_{j = 1}^5 X_j \beta_j\)</span>, one of the <span class="math notranslate nohighlight">\(X_j\)</span>s is one, and the others are zero</p></li>
<li><p>interactions between variables, for example, <span class="math notranslate nohighlight">\(X_3 = X_1 \cdot X_2\)</span></p></li>
</ol>
<p>no matter the source of the <span class="math notranslate nohighlight">\(X_j\)</span>, the model is linear in the parameters<br></p>
</div>
</div>
<div class="section" id="let-textbf-x-n-times-p-1-be-the-n-times-p-1-matrix-with-each-row-an-input-vector-br-textbf-x">
<h1>Let <span class="math notranslate nohighlight">\(\textbf{X}_{[N \times (p + 1)]}\)</span> be the <span class="math notranslate nohighlight">\(N \times (p + 1)\)</span> matrix with each row an input vector<br>
$$
\textbf{X}<a class="headerlink" href="#let-textbf-x-n-times-p-1-be-the-n-times-p-1-matrix-with-each-row-an-input-vector-br-textbf-x" title="Permalink to this headline">¶</a></h1>
</div>
<div class="section" id="begin-bmatrix-x-1-x-p-1-end-bmatrix">
<h1>\begin{bmatrix}
X_1 &amp; … &amp; X_{p + 1} \
\end{bmatrix}<a class="headerlink" href="#begin-bmatrix-x-1-x-p-1-end-bmatrix" title="Permalink to this headline">¶</a></h1>
<p>\begin{bmatrix}
x_{11} &amp; … &amp; x_{1, p + 1} \
… &amp; … &amp; … \
x_{N1} &amp; … &amp; x_{N, p + 1} \
\end{bmatrix}
$<span class="math notranslate nohighlight">\(
Let \)</span>\textbf{y}_{[N \times 1]}<span class="math notranslate nohighlight">\( be the \)</span>N$-vector of outputs in the training set<br></p>
<p>the <span class="math notranslate nohighlight">\(\beta_j\)</span>s are unknown parameters or coefficients<br>
Training Data may be used to estimate the parameters <span class="math notranslate nohighlight">\(\beta\)</span><br>
$<span class="math notranslate nohighlight">\(x = {(x_1, y_1), ..., (x_N, y_N)}\)</span><span class="math notranslate nohighlight">\(
\)</span><span class="math notranslate nohighlight">\(x_i = (x_{i1}, ..., x_{ip})^T\)</span>$
Parameter Estimation Methods:<br></p>
<ol class="simple">
<li><p>Least Squares</p></li>
</ol>
<p><strong>Least Squares Optimality Criterion</strong><br>
pick the coefficients <span class="math notranslate nohighlight">\(\beta = (\beta_0, ..., \beta_p)^T\)</span> to minimize the residual sum of squares</p>
<p><strong>Residual</strong><br>
$<span class="math notranslate nohighlight">\(\hat{y} - y\)</span>$</p>
<p><strong>RSS Residual Sum of Squares</strong><br>
measures the average lack of fit<br>
$<span class="math notranslate nohighlight">\(
\begin{align}
\text{RSS}(\beta)
&amp;= \sum_{i = 1}^N (y_i - f(x_i))^2 \\
&amp;= \sum_{i = 1}^N \left(y_i - \beta_0 - \sum_{j = 1}^p x_{ij} \beta_j \right)^2 \\
&amp;= (\textbf{y} - \textbf{X}\beta)^T (\textbf{y} - \textbf{X}\beta)
&amp; \,\,\,\text{this is a quadratic function in the}\, p + 1 \,\text{parameters} \\
&amp;= (\textbf{y}^T - \beta^T\textbf{X}^T) (\textbf{y} - \textbf{X}\beta) \\
&amp;= \textbf{y}^T\textbf{y} - \textbf{y}^T\textbf{X}\beta - \beta^T\textbf{X}^T\textbf{y} + \beta^T\textbf{X}^T\textbf{X}\beta \\
&amp;= \textbf{y}^T\textbf{y} - (\textbf{y}^T\textbf{X}\beta)^T - \beta^T\textbf{X}^T\textbf{y} + \beta^T\textbf{X}^T\textbf{X}\beta \\
&amp;= \textbf{y}^T\textbf{y} - \beta^T\textbf{X}^T\textbf{y} - \beta^T\textbf{X}^T\textbf{y} + \beta^T\textbf{X}^T\textbf{X}\beta \\
&amp;= \textbf{y}^T\textbf{y} - 2\beta^T\textbf{X}^T\textbf{y} + \beta^T\textbf{X}^T\textbf{X}\beta \\
\frac{\partial \text{RSS}}{\partial \beta} &amp;= -2\textbf{X}^T\textbf{y} + 2\textbf{X}^T\textbf{X}\beta \\
&amp;= -2\textbf{X}^T (\textbf{y} - \textbf{X} \beta)
&amp; \text{first partial derivative with respect to}\, \beta \\
\frac{\partial^2 \text{RSS}}{\partial \beta \partial \beta^T} &amp;= 2\textbf{X}^T \textbf{X}
&amp; \text{second partial derivative with respect to}\, \beta \\
0 &amp;= \textbf{X}^T (\textbf{y} - \textbf{X} \beta)
&amp; \text{set the first partial derivative to zero assuming X has full column rank} \\
\hat{\beta} &amp;= (\textbf{X}^T\textbf{X})^{-1} \textbf{X}^T \textbf{y}
&amp; \text{unique solution} \\
\hat{\textbf{y}} = \textbf{X} \hat{\beta} &amp;= \textbf{X} (\textbf{X}^T\textbf{X})^{-1} \textbf{X}^T \textbf{y}
\,\text{where}\, \hat{y}_i = \hat{f}(x_i)
&amp; \text{the fitted values at the training inputs} \\
\hat{\textbf{y}} = \textbf{Hy} &amp;= \textbf{X} (\textbf{X}^T\textbf{X})^{-1} \textbf{X}^T \textbf{y}
&amp; \text{Hat matrix}\, \textbf{H} = \textbf{X} (\textbf{X}^T\textbf{X})^{-1} \textbf{X}^T \\
\end{align}
\)</span>$</p>
<hr class="docutils" />
<p>Simple Linear Regression <span class="math notranslate nohighlight">\(\hat{y} = b_0 + b_1x\)</span> <br>
Least Squares (Least Sum of Squared Errors) <br>
    
<span class="math notranslate nohighlight">\(b_1 = \frac{\sum_i (x_i - \bar{x})(y_i - \bar{y})}{\sum_i (x_i - \bar{x})^2}\)</span> <br>
    
<span class="math notranslate nohighlight">\(b_0 = \bar{y} - b_1\bar{x}\)</span> <br>
Residual (Prediction Error) <span class="math notranslate nohighlight">\(= y - \hat{y}\)</span> <br>
Sum of Squared Errors SSE <span class="math notranslate nohighlight">\(= \sum (y - \hat{y})^2\)</span> <br></p>
<hr class="docutils" />
<p><strong>Linear Regression in <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span></strong>
$<span class="math notranslate nohighlight">\(
\begin{align}
f(X)
&amp; = \beta_0 + \sum_{j = 1}^1 X_j \beta_j \\
&amp; = \beta_0 + X_1 \beta_1 \\
\end{align}
\)</span>$</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\textbf{X}
=
\begin{bmatrix}
X_1 \\
\end{bmatrix}
=
\begin{bmatrix}
x_{11} \\
... \\
x_{N1} \\
\end{bmatrix}
\end{split}\]</div>
<hr class="docutils" />
<p><strong>Linear Regression in <span class="math notranslate nohighlight">\(\mathbb{R}^3\)</span></strong>
$<span class="math notranslate nohighlight">\(
\begin{align}
f(X)
&amp; = \beta_0 + \sum_{j = 1}^2 X_j \beta_j \\
&amp; = \beta_0 + X_1 \beta_1 + X_2 \beta_2 \\
\end{align}
\)</span>$</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\textbf{X}
=
\begin{bmatrix}
X_1 &amp; X_{2} \\
\end{bmatrix}
=
\begin{bmatrix}
x_{11} &amp; x_{12} \\
... &amp; ... \\
x_{N1} &amp; x_{N2} \\
\end{bmatrix}
\end{split}\]</div>
<hr class="docutils" />
<p>Linear Regression example implemented in scikit-learn</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> <span class="o">+</span> <span class="n">x</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_89_0.png" src="../_images/mathematical_foundations_89_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">intercept_</span>
<span class="n">predicted_y</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">predicted_y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_90_0.png" src="../_images/mathematical_foundations_90_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">predicted_y</span><span class="p">)</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">predicted_y</span><span class="p">)</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>
<span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span>
    <span class="n">score</span><span class="p">,</span>
    <span class="n">r2</span><span class="p">,</span>
    <span class="n">mse</span><span class="p">,</span>
    <span class="n">rmse</span><span class="p">,</span>
    <span class="n">std</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8254752151930345
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8254752151930345
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.07967345900040602
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.2822648738337911
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.675660111586674
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="generalized-linear-models-wiki">
<h2>Generalized Linear Models <a class="reference external" href="https://en.wikipedia.org/wiki/Generalized_linear_model">Wiki</a><a class="headerlink" href="#generalized-linear-models-wiki" title="Permalink to this headline">¶</a></h2>
<hr class="docutils" />
<hr class="docutils" />
</div>
</div>
<hr class="docutils" />
<div class="section" id="supervised-ml-classification">
<h1>Supervised ML: Classification<a class="headerlink" href="#supervised-ml-classification" title="Permalink to this headline">¶</a></h1>
<hr class="docutils" />
<p><strong>Classification</strong><br>
Binary Classification<br>
Multiclass Classification<br></p>
<hr class="docutils" />
<div class="section" id="classifiers">
<h2>Classifiers<a class="headerlink" href="#classifiers" title="Permalink to this headline">¶</a></h2>
<p><strong>ANN Artificial Neural Network</strong><br>
<strong>Decision Tree</strong><br>
<strong>Probabilistic Discriminative Model</strong><br>
a probabilistic classification model that directly assigns class labels without computing class-conditional probabilities<br>
    
Logistic Regression<br>
<strong>Probabilistic Generative Model</strong><br>
a probabilistic classification model that involves computing class-conditional probabilities<br>
    
Bayesian Classifiers<br>
        
Bayesian Network<br>
        
Naive Bayes<br>
<strong>KNN K-Nearest Neighbors</strong><br>
<strong>SVM Support Vector Machine</strong><br>
<strong>Ensembling</strong><br>
    
Bagging<br>
    
Boosting<br>
    
Random Forest<br></p>
</div>
<hr class="docutils" />
<div class="section" id="decision-tree">
<h2>Decision Tree<a class="headerlink" href="#decision-tree" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;vertebrate.csv&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="s1">&#39;infer&#39;</span><span class="p">)</span>
<span class="n">data</span>

<span class="n">data</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">([</span><span class="s1">&#39;fishes&#39;</span><span class="p">,</span> <span class="s1">&#39;birds&#39;</span><span class="p">,</span> <span class="s1">&#39;amphibians&#39;</span><span class="p">,</span> <span class="s1">&#39;reptiles&#39;</span><span class="p">],</span> <span class="s1">&#39;non-mammals&#39;</span><span class="p">)</span>
<span class="n">data</span>

<span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;Warm-blooded&#39;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Gives Birth&#39;</span><span class="p">]],</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">])</span>

<span class="n">Y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;Name&#39;</span><span class="p">,</span> <span class="s1">&#39;Class&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;entropy&#39;</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="n">dot_data</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">export_graphviz</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mammals&#39;</span><span class="p">,</span> <span class="s1">&#39;non-mammals&#39;</span><span class="p">],</span> <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">pydotplus</span><span class="o">.</span><span class="n">graph_from_dot_data</span><span class="p">(</span><span class="n">dot_data</span><span class="p">)</span>
<span class="n">Image</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">create_png</span><span class="p">())</span>

<span class="n">testData</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;gila monster&#39;</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;non-mammals&#39;</span><span class="p">],</span>
           <span class="p">[</span><span class="s1">&#39;platypus&#39;</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;mammals&#39;</span><span class="p">],</span>
           <span class="p">[</span><span class="s1">&#39;owl&#39;</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;non-mammals&#39;</span><span class="p">],</span>
           <span class="p">[</span><span class="s1">&#39;dolphin&#39;</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;mammals&#39;</span><span class="p">]]</span>
<span class="n">testData</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">testData</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="n">testY</span> <span class="o">=</span> <span class="n">testData</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
<span class="n">testX</span> <span class="o">=</span> <span class="n">testData</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;Name&#39;</span><span class="p">,</span> <span class="s1">&#39;Class&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">predY</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testX</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">testData</span><span class="p">[</span><span class="s1">&#39;Name&#39;</span><span class="p">],</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">predY</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Predicted Class&#39;</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">predictions</span>

<span class="n">accuracy_score</span><span class="p">(</span><span class="n">testY</span><span class="p">,</span> <span class="n">predY</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.75
</pre></div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="logistic-regression">
<h2>Logistic Regression<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">¶</a></h2>
<p>a probabilistic discriminative model</p>
<p><strong>Odds</strong><br>
$<span class="math notranslate nohighlight">\(\frac{P(y = 1 | \textbf{x})}{P(y = 0 | \textbf{x})}\)</span>$</p>
<p><strong>Logistic Regression</strong><br>
$<span class="math notranslate nohighlight">\(
\begin{align}
P(y = 1 | x)
&amp;= \frac{1}{1 + \text{exp}^{-w^Tx - b}} \\
&amp;= \sigma(w^Tx + b) \\
\end{align}
\)</span><span class="math notranslate nohighlight">\(
the model parameters \)</span>(w, b)<span class="math notranslate nohighlight">\( are estimated by optimizing the following regularized negative log-likelihood function&lt;br&gt;
\)</span><span class="math notranslate nohighlight">\((w*, b*) = \text{argmin}_{w, b} - \sum_{i = 1}^N y_i \text{log} \left[ \sigma(w^Tx_i + b) \right] + (1 - y_i) \text{log} \left[ \sigma(w^Tx_i + b) \right] + \frac{1}{C} \Omega ([w, b])\)</span><span class="math notranslate nohighlight">\(
where \)</span>C<span class="math notranslate nohighlight">\( is a hyperparameter that controls the inverse of model complexity (smaller values imply stronger regularization) while \)</span>\Omega(\cdot)<span class="math notranslate nohighlight">\( is the regularization term, which by default, is assumed to be an \)</span>l_2$-norm in sklearn<br></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">1500</span>
<span class="n">mean1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">14</span><span class="p">]</span>  <span class="c1"># center of first Gaussian distribution</span>
<span class="n">mean2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>  <span class="c1"># center of second Gaussian distribution</span>
<span class="n">mean3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">]</span> <span class="c1"># center of third Gaussian distribution</span>
<span class="n">cov</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">3.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">]]</span> <span class="c1"># diagonal covariance</span>
<span class="n">npr</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">6</span><span class="p">))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">npr</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean2</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">6</span><span class="p">))))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">npr</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean3</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">6</span><span class="p">))))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="mi">20</span><span class="o">*</span><span class="n">npr</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">))))</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">C</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">]</span>
<span class="n">LRtrainAcc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">LRtestAcc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">C</span><span class="p">:</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">param</span><span class="p">)</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
    <span class="n">Y_predTrain</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">Y_predTest</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">LRtrainAcc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_predTrain</span><span class="p">))</span>
    <span class="n">LRtestAcc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">Y_predTest</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">LRtrainAcc</span><span class="p">,</span> <span class="s1">&#39;ro-&#39;</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">LRtestAcc</span><span class="p">,</span> <span class="s1">&#39;bv--&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Training Accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;Test Accuracy&#39;</span><span class="p">]);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;C&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_107_0.png" src="../_images/mathematical_foundations_107_0.png" />
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="knn-k-nearest-neighbors-classifier">
<h2>KNN K-Nearest Neighbors Classifier<a class="headerlink" href="#knn-k-nearest-neighbors-classifier" title="Permalink to this headline">¶</a></h2>
<p><strong>KNN</strong><br>
the class label of a test instance is predicted based on the majority class of its <span class="math notranslate nohighlight">\(k\)</span> closest training instances<br>
the number of nearest neighbors <span class="math notranslate nohighlight">\(k\)</span> is a hyperparameter that must be provided by the user, along with the distance metric<br></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">1500</span>
<span class="n">mean1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">14</span><span class="p">]</span>  <span class="c1"># center of first Gaussian distribution</span>
<span class="n">mean2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>  <span class="c1"># center of second Gaussian distribution</span>
<span class="n">mean3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">]</span> <span class="c1"># center of third Gaussian distribution</span>
<span class="n">cov</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">3.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">]]</span> <span class="c1"># diagonal covariance</span>
<span class="n">npr</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">6</span><span class="p">))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">npr</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean2</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">6</span><span class="p">))))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">npr</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean3</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">6</span><span class="p">))))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="mi">20</span><span class="o">*</span><span class="n">npr</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">))))</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">numNeighbors</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">30</span><span class="p">]</span>
<span class="n">trainAcc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">testAcc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">numNeighbors</span><span class="p">:</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;minkowski&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
    <span class="n">Y_predTrain</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">Y_predTest</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">trainAcc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_predTrain</span><span class="p">))</span>
    <span class="n">testAcc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">Y_predTest</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">numNeighbors</span><span class="p">,</span> <span class="n">trainAcc</span><span class="p">,</span> <span class="s1">&#39;ro-&#39;</span><span class="p">,</span> <span class="n">numNeighbors</span><span class="p">,</span> <span class="n">testAcc</span><span class="p">,</span> <span class="s1">&#39;bv--&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Training Accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;Test Accuracy&#39;</span><span class="p">]);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of neighbors&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_111_0.png" src="../_images/mathematical_foundations_111_0.png" />
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="svm-support-vector-machine">
<h2>SVM Support Vector Machine<a class="headerlink" href="#svm-support-vector-machine" title="Permalink to this headline">¶</a></h2>
<p>the model parameters <span class="math notranslate nohighlight">\((w*, b*)\)</span> are estimated by solving the following constrained optimization problem:<br>
$<span class="math notranslate nohighlight">\(
\begin{align}
&amp; \text{min}_{w*, b*, {\xi_i}} \frac{|| w ||^2}{2} + \frac{1}{C} \sum_i \xi_i
&amp; \text{s.t.}\, \forall i : y_i \left[ w^T \phi(x_i) + b \right] \ge 1 - \xi_i, \xi_i \ge 0 \\
\end{align}
\)</span>$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">1500</span>
<span class="n">mean1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">14</span><span class="p">]</span>  <span class="c1"># center of first Gaussian distribution</span>
<span class="n">mean2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>  <span class="c1"># center of second Gaussian distribution</span>
<span class="n">mean3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">]</span> <span class="c1"># center of third Gaussian distribution</span>
<span class="n">cov</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">3.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">]]</span> <span class="c1"># diagonal covariance</span>
<span class="n">npr</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">6</span><span class="p">))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">npr</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean2</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">6</span><span class="p">))))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">npr</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean3</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">6</span><span class="p">))))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="mi">20</span><span class="o">*</span><span class="n">npr</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">))))</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">C</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">]</span>
<span class="n">SVMtrainAcc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">SVMtestAcc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">C</span><span class="p">:</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">param</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">)</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
    <span class="n">Y_predTrain</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">Y_predTest</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">SVMtrainAcc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_predTrain</span><span class="p">))</span>
    <span class="n">SVMtestAcc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">Y_predTest</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">SVMtrainAcc</span><span class="p">,</span> <span class="s1">&#39;ro-&#39;</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">SVMtestAcc</span><span class="p">,</span> <span class="s1">&#39;bv--&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Training Accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;Test Accuracy&#39;</span><span class="p">]);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;C&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_115_0.png" src="../_images/mathematical_foundations_115_0.png" />
</div>
</div>
<hr class="docutils" />
<p>an example of a nonlinear SVM with a Gaussian radial basis function kernel<br></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">1500</span>
<span class="n">mean1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">14</span><span class="p">]</span>  <span class="c1"># center of first Gaussian distribution</span>
<span class="n">mean2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>  <span class="c1"># center of second Gaussian distribution</span>
<span class="n">mean3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">]</span> <span class="c1"># center of third Gaussian distribution</span>
<span class="n">cov</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">3.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">]]</span> <span class="c1"># diagonal covariance</span>
<span class="n">npr</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">6</span><span class="p">))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">npr</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean2</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">6</span><span class="p">))))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">npr</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean3</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">6</span><span class="p">))))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="mi">20</span><span class="o">*</span><span class="n">npr</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">))))</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">C</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">]</span>
<span class="n">SVMtrainAcc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">SVMtestAcc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">C</span><span class="p">:</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">param</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
    <span class="n">Y_predTrain</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">Y_predTest</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">SVMtrainAcc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_predTrain</span><span class="p">))</span>
    <span class="n">SVMtestAcc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">Y_predTest</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">SVMtrainAcc</span><span class="p">,</span> <span class="s1">&#39;ro-&#39;</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">SVMtestAcc</span><span class="p">,</span> <span class="s1">&#39;bv--&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Training Accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;Test Accuracy&#39;</span><span class="p">]);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;C&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_118_0.png" src="../_images/mathematical_foundations_118_0.png" />
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="ensembling">
<h2>Ensembling<a class="headerlink" href="#ensembling" title="Permalink to this headline">¶</a></h2>
<p>an ensemble classifier constructs a sett of base classifiers from the training data and performs classification by taking a vote on the predictions made by each base classifier<br></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">1500</span>
<span class="n">mean1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">14</span><span class="p">]</span>  <span class="c1"># center of first Gaussian distribution</span>
<span class="n">mean2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>  <span class="c1"># center of second Gaussian distribution</span>
<span class="n">mean3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">]</span> <span class="c1"># center of third Gaussian distribution</span>
<span class="n">cov</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">3.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">]]</span> <span class="c1"># diagonal covariance</span>
<span class="n">npr</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">6</span><span class="p">))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">npr</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean2</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">6</span><span class="p">))))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">npr</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean3</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">6</span><span class="p">))))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="mi">20</span><span class="o">*</span><span class="n">npr</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="p">))))</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">numBaseClassifiers</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">maxdepth</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">trainAcc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">testAcc</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">numBaseClassifiers</span><span class="p">)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
<span class="n">Y_predTrain</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">Y_predTest</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">trainAcc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_predTrain</span><span class="p">))</span>
<span class="n">testAcc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">Y_predTest</span><span class="p">))</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">maxdepth</span><span class="p">),</span> <span class="n">n_estimators</span><span class="o">=</span><span class="n">numBaseClassifiers</span><span class="p">)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
<span class="n">Y_predTrain</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">Y_predTest</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">trainAcc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_predTrain</span><span class="p">))</span>
<span class="n">testAcc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">Y_predTest</span><span class="p">))</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">maxdepth</span><span class="p">),</span> <span class="n">n_estimators</span><span class="o">=</span><span class="n">numBaseClassifiers</span><span class="p">)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
<span class="n">Y_predTrain</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">Y_predTest</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">trainAcc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_predTrain</span><span class="p">))</span>
<span class="n">testAcc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">Y_predTest</span><span class="p">))</span>

<span class="n">methods</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Random Forest&#39;</span><span class="p">,</span> <span class="s1">&#39;Bagging&#39;</span><span class="p">,</span> <span class="s1">&#39;AdaBoost&#39;</span><span class="p">]</span>
<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">],</span> <span class="n">trainAcc</span><span class="p">);</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">]);</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">methods</span><span class="p">);</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">],</span> <span class="n">testAcc</span><span class="p">);</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">]);</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">methods</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_122_0.png" src="../_images/mathematical_foundations_122_0.png" />
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="binary-classification-performance-evaluation-wiki">
<h2>Binary Classification Performance Evaluation <a class="reference external" href="https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers">Wiki</a><a class="headerlink" href="#binary-classification-performance-evaluation-wiki" title="Permalink to this headline">¶</a></h2>
<table>
    <tr>
        <td>
<table>
    <caption>Binary Confusion Matrix</caption>
    <!-- the number of columns in the table -->
    <col>
    <col>
    <colgroup span="2"></colgroup>
    <thead>
        <tr>
            <td colspan="2" rowspan="2"></td>
            <th colspan="2" scope="colgroup">Predicted</th>
        </tr>
        <tr>
            <th scope="col">+</th>
            <th scope="col">-</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <th rowspan="4" scope="rowgroup">Actual</th>
            <th scope="row" style="border-right: 1px solid black;">+</th>
            <td style="background-color: coral;">$$\text{TP}$$</td>
            <td>$$\text{FN}$$</td>
        </tr>
        <tr></tr> <!-- get rid of zebra stripes -->
        <tr>
            <th scope="row" style="border-right: 1px solid black;">-</th>
            <td>$$\text{FP}$$</td>
            <td style="background-color: coral;">$$\text{TN}$$</td>
        </tr>
        <tr></tr> <!-- get rid of zebra stripes -->
    </tbody>
</table>
        </td><td>
<table>
    <caption>Binary Confusion Matrix</caption>
    <!-- the number of columns in the table -->
    <col>
    <col>
    <colgroup span="2"></colgroup>
    <thead>
        <tr>
            <td colspan="2" rowspan="2"></td>
            <th colspan="2" scope="colgroup">Predicted</th>
        </tr>
        <tr>
            <th scope="col">0</th>
            <th scope="col">1</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <th rowspan="4" scope="rowgroup">Actual</th>
            <th scope="row" style="border-right: 1px solid black;">0</th>
            <td style="background-color: coral;">$$f_{00}$$</td>
            <td>$$f_{01}$$</td>
        </tr>
        <tr></tr> <!-- get rid of zebra stripes -->
        <tr>
            <th scope="row" style="border-right: 1px solid black;">1</th>
            <td>$$f_{10}$$</td>
            <td style="background-color: coral;">$$f_{11}$$</td>
        </tr>
        <tr></tr> <!-- get rid of zebra stripes -->
    </tbody>
</table>
        </td>
    </tr>
</table><p><span class="math notranslate nohighlight">\(f_{ij}\)</span> is the number of instances from class <span class="math notranslate nohighlight">\(i\)</span> predicted to be of class <span class="math notranslate nohighlight">\(j\)</span> (here, class 0 is positive and class 1 is negative)<br></p>
<p><strong>TP True Positive</strong> is the number of positive examples correctly predicted by the classifier <span class="math notranslate nohighlight">\(f_{00}\)</span><br></p>
<p><strong>FP False Positive (Type I Error)</strong> is the number of negative examples wrongly predicted as positive by the classifier <span class="math notranslate nohighlight">\(f_{10}\)</span><br></p>
<p><strong>FN False Negative (Type II Error)</strong> is the number of positive examples wrongly predicted as negative by the classifier <span class="math notranslate nohighlight">\(f_{01}\)</span><br></p>
<p><strong>TN True Negative</strong> is the number of negative examples correctly predicted by the classifier <span class="math notranslate nohighlight">\(f_{11}\)</span><br></p>
<p><strong><span class="math notranslate nohighlight">\(\text{T}\)</span> number of correct predictions made by the model</strong><br>
$<span class="math notranslate nohighlight">\(
\begin{align}
\text{T} &amp;\equiv \text{TP} + \text{TN} \\
&amp;= \sum f_{ij} \,(\text{where}\, i = j) \\
&amp;= \sum_{i = 0}^1 f_{ii} \\
&amp;= f_{00} + f_{11} \\
\end{align}
\)</span>$</p>
<p><strong><span class="math notranslate nohighlight">\(\text{F}\)</span> number of incorrect predictions made by the model</strong><br>
$<span class="math notranslate nohighlight">\(
\begin{align}
\text{F} &amp;\equiv \text{FN} + \text{FP} \\
&amp;= \sum f_{ij} \,(\text{where}\, i \ne j) \\
&amp;= \sum_{j \ne i}^1 \sum_{i \ne j}^1 f_{ij} \\
&amp;= \sum_{j \ne i}^1 (f_{0j} + f_{1j}) \\
&amp;= \sum_{j \ne i}^1 f_{0j} + \sum_{j \ne i}^1 f_{1j} \\
&amp;= f_{01} + f_{10} \\
\end{align}
\)</span>$</p>
<p><strong><span class="math notranslate nohighlight">\(\text{N}\)</span> number of predictions made by the model</strong><br>
$<span class="math notranslate nohighlight">\(
\begin{align}
\text{N} &amp;\equiv \text{T} + \text{F} \\
&amp;= \text{TP} + \text{FP} + \text{FN} + \text{TN} \\
&amp;= \sum f_{ij} \\
&amp;= \sum_{j = 0}^1 \sum_{i = 0}^1 f_{ij} \\
&amp;= \sum_{j = 0}^1 (f_{0j} + f_{1j}) \\
&amp;= \sum_{j = 0}^1 f_{0j} + \sum_{j = 0}^1 f_{1j} \\
&amp;= f_{00} + f_{01} + f_{10} + f_{11} \\
\end{align}
\)</span>$</p>
<p><strong>Skew</strong> <span class="math notranslate nohighlight">\(\alpha\)</span> is the ratio of positive data objects to all data objects<br>
$<span class="math notranslate nohighlight">\(
\begin{align}
\alpha &amp;= \frac{P}{P + N} &amp; \text{where}\, P \,\text{is the number of actual positives and}\, N \,\text{is the number of actual negatives}
\end{align}
\)</span>$</p>
<div class="section" id="evaluation-measures">
<h3>Evaluation Measures<a class="headerlink" href="#evaluation-measures" title="Permalink to this headline">¶</a></h3>
<p><strong>Accuracy</strong> <span class="math notranslate nohighlight">\(a\)</span> is the ratio of correct predictions to all predictions, and takes a value <span class="math notranslate nohighlight">\(\in [0, 1]\)</span>, where <span class="math notranslate nohighlight">\(a = 1\)</span> is a perfect accuracy<br></p>
<p>        
suitable for balanced classes; not suitable for imbalanced classes, since it favors classifiers that correctly classify the majority class<br></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
a
&amp;= \frac{\text{TP} + \text{TN}}{\text{TP} + \text{FP} + \text{FN} + \text{TN}} \\
&amp;= \frac{\text{T}}{\text{N}} \\
\end{align}
\end{split}\]</div>
<p><strong>Error Rate</strong> <span class="math notranslate nohighlight">\(e\)</span> is the ratio of incorrect predictions to all predictions, and takes a value <span class="math notranslate nohighlight">\(\in [0, 1]\)</span>, where <span class="math notranslate nohighlight">\(e = 1\)</span> is a perfect error rate<br>
$<span class="math notranslate nohighlight">\(
\begin{align}
e
&amp;= 1 - a
&amp; \text{as the accuracy gets closer to unity, the error rate gets closer to zero, and vice versa} \\
&amp;= \frac{\text{FP} + \text{FN}}{\text{TP} + \text{FP} + \text{FN} + \text{TN}} \\
&amp;= \frac{\text{F}}{\text{N}} \\
\end{align}
\)</span>$</p>
<p><strong>Precision</strong> <span class="math notranslate nohighlight">\(p\)</span> (PPV Positive Predicted Value) is the ratio of correct predictions of the positive class to the total number of positive predictions<br></p>
<p>        
sensitive to skew: precision is a useful measure for highly skewed test sets where the positive predictions, even though small in number, are required to be mostly correct<br>
        
a classifier that has a high precision is likely to have most of its positive predictions correct<br></p>
<div class="math notranslate nohighlight">
\[p = \frac{\text{TP}}{\text{TP} + \text{FP}}\]</div>
<p><strong>FDR False Discovery Rate</strong><br></p>
<p>        
this evaluation measure is sensitive to the skew<br></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\text{FDR}
&amp;= 1 - p \\
&amp;= \frac{\text{FP}}{\text{TP} + \text{FP}} \\
\end{align}
\end{split}\]</div>
<p><em>as the precision gets closer to unity, the false discovery rate gets closer to zero, and vice versa</em><br></p>
<p><strong>TPR True Positive Rate (Recall or Sensitivity)</strong><br>
the fraction of positive test instances correctly predicted by the classifier<br></p>
<p>        
a classifier with a high TPR has a high chance of correctly identifying the positive instances of the data<br>
        
this evaluation measure is not sensitive to the skew<br></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\text{TPR}
&amp;= \frac{\text{TP}}{\text{TP} + \text{FN}} \\
&amp;= \frac{\text{TP}}{P} \\
\end{align}
\end{split}\]</div>
<p><strong>TNR True Negative Rate (Specificity)</strong><br>
the fraction of negative test instances correctly predicted by the classifier<br></p>
<p>        
a high TNR value signifies that the classifier correctly classifies any randomly chosen negative instance in the test set<br>
        
this evaluation measure is not sensitive to the skew<br></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\text{TNR}
&amp;= \frac{\text{TN}}{\text{FP} + \text{TN}} \\
&amp;= \frac{\text{TN}}{N} \\
\end{align}
\end{split}\]</div>
<p><strong>FPR False Positive Rate</strong><br></p>
<p>        
this evaluation measure is not sensitive to the skew<br></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\text{FPR}
&amp;= 1 - \text{TNR} \\
&amp;= \frac{\text{FP}}{\text{FP} + \text{TN}} \\
&amp;= \frac{\text{FP}}{N} \\
\end{align}
\end{split}\]</div>
<p><strong>FNR False Negative Rate</strong><br></p>
<p>        
this evaluation measure is not sensitive to the skew<br></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\text{FNR}
&amp;= 1 - \text{TPR} \\
&amp;= \frac{\text{FN}}{\text{FN} + \text{TP}} \\
&amp;= \frac{\text{FN}}{P} \\
\end{align}
\end{split}\]</div>
<table>
    <caption>Binary Confusion Matrix</caption>
    <!-- the number of columns in the table -->
    <col>
    <col>
    <colgroup span="2"></colgroup>
    <thead>
        <tr>
            <td colspan="2" rowspan="2"></td>
            <th colspan="2" scope="colgroup">Predicted</th>
        </tr>
        <tr>
            <th scope="col">+</th>
            <th scope="col">-</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <th rowspan="4" scope="rowgroup">Actual</th>
            <th scope="row" style="border-right: 1px solid black;">+</th>
            <td style="background-color: coral;">$$\text{TPR} \times \alpha \times \text{N}$$</td>
            <td>$$(1 - \text{TPR}) \times \alpha \times \text{N}$$</td>
            <td>$$\alpha \times \text{N}$$</td>
        </tr>
        <tr></tr> <!-- get rid of zebra stripes -->
        <tr>
            <th scope="row" style="border-right: 1px solid black;">-</th>
            <td>$$(1 - \text{TNR}) \times (1 - \alpha) \times \text{N}$$</td>
            <td style="background-color: coral;">$$\text{TNR} \times (1 - \alpha) \times \text{N}$$</td>
            <td>$$(1 - \alpha) \times \text{N}$$</td>
        </tr>
        <tr></tr> <!-- get rid of zebra stripes -->
    </tbody>
    <tbody>
        <tr>
            <th rowspan="2" scope="rowgroup">Total</th>
            <td style="border-right: 1px solid black;"></td>
            <td></td>
            <td></td>
            <td>$$\text{N}$$</td>
        </tr>
    </tbody>
</table><p>PLR <strong>Positive Likelihood Ratio</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/Likelihood_function#Likelihood_ratio">Wiki</a> <a class="reference external" href="https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing">Wiki</a><br>
not sensitive to skew<br>
$<span class="math notranslate nohighlight">\(\text{PLR} = \frac{\text{TPR}}{\text{FPR}}\)</span>$</p>
<p><span class="math notranslate nohighlight">\(F_1\)</span> <strong>Measure</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/F-score">Wiki</a> is the harmonic mean of recall and precision<br>
a high <span class="math notranslate nohighlight">\(F_1\)</span>-measure value ensures that both precision and recall are reasonably high, since the harmonic mean of two numbers tends to be closer to the smaller of the two numbers<br>
sensitive to skew<br>
$<span class="math notranslate nohighlight">\(
\begin{align}
F_1
&amp;= \frac{2rp}{r + p} = \frac{2}{\frac{1}{r} + \frac{1}{p}}\\
&amp;= \frac{2 \times \text{TP}}{2 \times \text{TP} + \text{FP} + \text{FN}} \\
&amp;= \frac{2 \times f_{00}}{2 \times f_{00} + f_{10} + f_{01}} \\
\end{align}
\)</span>$</p>
<p><span class="math notranslate nohighlight">\(F_{\beta}\)</span> <strong>Measure</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/F-score">Wiki</a><br>
$<span class="math notranslate nohighlight">\(
\begin{align}
F_{\beta}
&amp;= \frac{(\beta^2 + 1)rp}{r + \beta^2p}
= \frac{\beta^2rp + rp}{r + \beta^2p}
= \frac{rp + \frac{rp}{\beta^2}}{\frac{r}{\beta^2} + p} \\
&amp;= \frac{(\beta^2 + 1)\text{TP}}{(\beta^2 + 1)\text{TP} + \beta^2\text{FP} + \text{FN}} \\
\end{align}
\)</span>$</p>
<p>as <span class="math notranslate nohighlight">\(\beta\)</span> approaches <span class="math notranslate nohighlight">\(0\)</span>, <span class="math notranslate nohighlight">\(F_{\beta}\)</span> approaches <span class="math notranslate nohighlight">\(p\)</span><br>
<span class="math notranslate nohighlight">\(
F_{0}
= \frac{(0 + 1)rp}{r + 0p}
= \frac{rp}{r}
= p
\)</span></p>
<p>as <span class="math notranslate nohighlight">\(\beta\)</span> approaches <span class="math notranslate nohighlight">\(\infty\)</span>, <span class="math notranslate nohighlight">\(F_{\beta}\)</span> approaches <span class="math notranslate nohighlight">\(r\)</span><br>
<span class="math notranslate nohighlight">\(
F_{\infty}
= \frac{rp + \frac{rp}{\infty}}{\frac{r}{\infty} + p}
= \frac{rp}{p}
= r
\)</span></p>
<p><span class="math notranslate nohighlight">\(G\)</span> <strong>Measure</strong> is the geometric mean of recall and precision<br>
$<span class="math notranslate nohighlight">\(
\begin{align}
G
&amp;= \sqrt{rp} \\
&amp;= \frac{\text{TP}}{\sqrt{(\text{TP} + \text{FP})(\text{TP} + \text{FN})}} \\
&amp;= \frac{f_{00}}{\sqrt{(f_{00} + f_{10})(f_{00} + f_{01})}} \\
\end{align}
\)</span>$</p>
<p>AIC <strong>Akaike Information Criterion</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/Akaike_information_criterion">Wiki</a><br>
$<span class="math notranslate nohighlight">\(\text{AIC} = 2k - 2 \,\text{ln}\, (\hat{L})\)</span><span class="math notranslate nohighlight">\(
where \)</span>\hat{L} = p(x | \hat{\theta}, M)<span class="math notranslate nohighlight">\( is the maximized value of the likelihood function of the model and \)</span>k$ is the number of parameters estimated by the model<br></p>
<p>BIC <strong>Bayesian Information Criterion</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/Bayesian_information_criterion">Wiki</a><br>
$<span class="math notranslate nohighlight">\(\text{BIC} = k \,\text{ln}\, (n) - 2 \,\text{ln}\, (\hat{L})\)</span><span class="math notranslate nohighlight">\(
where \)</span>\hat{L} = p(x | \hat{\theta}, M)<span class="math notranslate nohighlight">\( is the maximized value of the likelihood function of the model, \)</span>n<span class="math notranslate nohighlight">\( is the number of data points in \)</span>x<span class="math notranslate nohighlight">\(, and \)</span>k$ is the number of parameters estimated by the model<br></p>
<hr class="docutils" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">b</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">mu_a</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>         <span class="c1"># arithmetic mean</span>
<span class="n">mu_g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">a</span> <span class="o">*</span> <span class="n">b</span><span class="p">)</span>      <span class="c1"># geometric mean</span>
<span class="n">mu_h</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">a</span> <span class="o">*</span> <span class="n">b</span> <span class="o">/</span> <span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="c1"># harmonic mean</span>
<span class="n">display</span><span class="p">(</span><span class="n">mu_a</span><span class="p">,</span> <span class="n">mu_g</span><span class="p">,</span> <span class="n">mu_h</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.0
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.23606797749979
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.6666666666666667
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">c1</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">c2</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">TP</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">3e1</span> <span class="o">*</span> <span class="n">c1</span><span class="p">)</span>
<span class="n">FP</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">2e1</span> <span class="o">*</span> <span class="n">c2</span><span class="p">)</span>
<span class="n">FN</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">0</span> <span class="o">*</span> <span class="n">c1</span><span class="p">)</span>
<span class="n">TN</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">5e1</span> <span class="o">*</span> <span class="n">c2</span><span class="p">)</span>

<span class="n">T</span>  <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">TN</span><span class="p">)</span> <span class="c1"># correct</span>
<span class="n">F</span>  <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span> <span class="c1"># incorrect</span>
<span class="n">AP</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span> <span class="c1"># actual positive</span>
<span class="n">AN</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span> <span class="c1"># actual negative</span>
<span class="n">PP</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span> <span class="c1"># predicted positive</span>
<span class="n">PN</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">TN</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span> <span class="c1"># predicted negative</span>
<span class="n">N</span>  <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span> <span class="o">+</span> <span class="n">TN</span><span class="p">)</span> <span class="c1"># all</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="n">AP</span> <span class="o">/</span> <span class="n">N</span>

<span class="n">accuracy</span>             <span class="o">=</span> <span class="n">T</span> <span class="o">/</span> <span class="n">N</span>   <span class="c1"># correct over all</span>
<span class="n">error_rate</span>           <span class="o">=</span> <span class="n">F</span> <span class="o">/</span> <span class="n">N</span>   <span class="c1"># incorrect over all</span>
<span class="n">precision</span>            <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="n">PP</span> <span class="c1"># correct positive over all positive</span>
<span class="n">false_discovery_rate</span> <span class="o">=</span> <span class="n">FP</span> <span class="o">/</span> <span class="n">PP</span> <span class="c1"># incorrect positive over all positive</span>

<span class="n">true_positive_rate</span>   <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="n">AP</span> <span class="c1"># correct positive over actual positive</span>
<span class="n">false_negative_rate</span>  <span class="o">=</span> <span class="n">FN</span> <span class="o">/</span> <span class="n">AP</span> <span class="c1"># incorrect negative over actual positive</span>
<span class="n">true_negative_rate</span>   <span class="o">=</span> <span class="n">TN</span> <span class="o">/</span> <span class="n">AN</span> <span class="c1"># correct negative over actual negative</span>
<span class="n">false_positive_rate</span>  <span class="o">=</span> <span class="n">FP</span> <span class="o">/</span> <span class="n">AN</span> <span class="c1"># incorrect positive over actual negative</span>

<span class="n">lines</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;pred+&#39;</span><span class="p">,</span> <span class="s1">&#39;pred-&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">),</span>
    <span class="s1">&#39;</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;act+&#39;</span><span class="p">,</span> <span class="n">TP</span><span class="p">,</span> <span class="n">FN</span><span class="p">,</span> <span class="n">AP</span><span class="p">),</span>
    <span class="s1">&#39;</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;act-&#39;</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">TN</span><span class="p">,</span> <span class="n">AN</span><span class="p">),</span>
    <span class="s1">&#39;</span><span class="se">\t\t\t</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">N</span><span class="p">),</span>
    <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="s1">&#39;</span><span class="si">{:5}{:0.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\u03b1</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
    <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="s1">&#39;</span><span class="si">{:5}{:0.3f}</span><span class="se">\t</span><span class="si">{:5}{:0.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">accuracy</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s1">&#39;e&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">error_rate</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
    <span class="s1">&#39;</span><span class="si">{:5}{:0.3f}</span><span class="se">\t</span><span class="si">{:5}{:0.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;p&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s1">&#39;fdr&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">false_discovery_rate</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
    <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="s1">&#39;</span><span class="si">{:5}{:0.3f}</span><span class="se">\t</span><span class="si">{:5}{:0.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">true_positive_rate</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s1">&#39;fnr&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">false_negative_rate</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
    <span class="s1">&#39;</span><span class="si">{:5}{:0.3f}</span><span class="se">\t</span><span class="si">{:5}{:0.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;tnr&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">true_negative_rate</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s1">&#39;fpr&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">false_positive_rate</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
<span class="p">]</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>	pred+	pred-	
act+	30	0	30
act-	20	50	70
			100

α    0.300

a    0.800	e    0.200
p    0.600	fdr  0.400

r    1.000	fnr  0.000
tnr  0.714	fpr  0.286
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="multiclass-classification-performance-evaluation">
<h2>Multiclass Classification Performance Evaluation<a class="headerlink" href="#multiclass-classification-performance-evaluation" title="Permalink to this headline">¶</a></h2>
<p>each entry <span class="math notranslate nohighlight">\(f_{ij}\)</span> is the number of instances from class <span class="math notranslate nohighlight">\(i\)</span> predicted to be of class <span class="math notranslate nohighlight">\(j\)</span><br></p>
<table>
    <caption>Multiclass Confusion Matrix</caption>
    <!-- the number of columns in the table -->
    <col>
    <col>
    <colgroup span="5"></colgroup>
    <thead>
        <tr>
            <td colspan="2" rowspan="2"></td>
            <th colspan="5" scope="colgroup">Predicted</th>
        </tr>
        <tr>
            <th scope="col">0</th>
            <th scope="col">1</th>
            <th scope="col">2</th>
            <th scope="col">...</th>
            <th scope="col">k</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <th rowspan="9" scope="rowgroup">Actual</th>
            <th scope="row" style="border-right: 1px solid black;">0</th>
            <td style="background-color: coral;">$$f_{00}$$</td>
            <td>$$f_{01}$$</td>
            <td>$$f_{02}$$</td>
            <td>$$...$$</td>
            <td>$$f_{0k}$$</td>
        </tr>
        <tr></tr> <!-- get rid of zebra stripes -->
        <tr>
            <th scope="row" style="border-right: 1px solid black;">1</th>
            <td>$$f_{10}$$</td>
            <td style="background-color: coral;">$$f_{11}$$</td>
            <td>$$f_{12}$$</td>
            <td>$$...$$</td>
            <td>$$f_{1k}$$</td>
        </tr>
        <tr></tr> <!-- get rid of zebra stripes -->
        <tr>
            <th scope="row" style="border-right: 1px solid black;">2</th>
            <td>$$f_{20}$$</td>
            <td>$$f_{21}$$</td>
            <td style="background-color: coral;">$$f_{22}$$</td>
            <td>$$...$$</td>
            <td>$$f_{2k}$$</td>
        </tr>
        <tr></tr> <!-- get rid of zebra stripes -->
        <tr>
            <th scope="row" style="border-right: 1px solid black;">$$\vdots$$</th>
            <td>$$\vdots$$</td>
            <td>$$\vdots$$</td>
            <td>$$\vdots$$</td>
            <td>$$\ddots$$</td>
            <td>$$\vdots$$</td>
        </tr>
        <tr></tr> <!-- get rid of zebra stripes -->
        <tr>
            <th scope="row" style="border-right: 1px solid black;">k</th>
            <td>$$f_{k0}$$</td>
            <td>$$f_{k1}$$</td>
            <td>$$f_{k2}$$</td>
            <td>$$...$$</td>
            <td style="background-color: coral;">$$f_{kk}$$</td>
        </tr>
    </tbody>
</table>
<p><strong><span class="math notranslate nohighlight">\(\text{T}\)</span> number of correct predictions made by the model</strong><br>
$<span class="math notranslate nohighlight">\(
\begin{align}
&amp; \sum f_{ij} \,(\text{where}\, i = j) \\
&amp;= \sum_{i = 0}^k f_{ii} \\
&amp;= f_{00} + f_{11} + ... + f_{kk}
&amp; k \,\text{times} \\
&amp;= \text{T}
&amp; k \,\text{terms} \\
\end{align}
\)</span>$</p>
<p><strong><span class="math notranslate nohighlight">\(\text{F}\)</span> number of incorrect predictions made by the model</strong><br>
$<span class="math notranslate nohighlight">\(
\begin{align}
&amp; \sum f_{ij} \,(\text{where}\, i \ne j) \\
&amp;= \sum_{j \ne i}^k \sum_{i \ne j}^k f_{ij} \\
&amp;= \sum_{j \ne i}^k (f_{0j} + f_{1j} + ... + f_{kj}) \\
&amp;= \sum_{j \ne i}^k f_{0j} + \sum_{j \ne i}^k f_{1j} + ... + \sum_{j \ne i}^k f_{kj} \\
&amp;= \underbrace{(f_{01} + f_{02} + ... + f_{0k})}_{k - 1 \,\text{terms}} + \underbrace{(f_{10} + f_{12} + ... + f_{1k})}_{k - 1 \,\text{terms}} + ... + \underbrace{(f_{k0} + f_{k1} + ... + f_{k, k - 1})}_{k - 1 \,\text{terms}}
&amp; k \,\text{times} \\
&amp;= \text{F}
&amp; k(k - 1) = k^2 - k \,\text{terms}\\
\end{align}
\)</span>$</p>
<p><strong><span class="math notranslate nohighlight">\(\text{N}\)</span> number of predictions made by the model</strong><br>
$<span class="math notranslate nohighlight">\(
\begin{align}
&amp; \sum f_{ij} \\
&amp;= \sum_{j = 0}^k \sum_{i = 0}^k f_{ij} \\
&amp;= \sum_{j = 0}^k (f_{0j} + f_{1j} + ... + f_{kj}) \\
&amp;= \sum_{j = 0}^k f_{0j} + \sum_{j = 0}^k f_{1j} + ... + \sum_{j = 0}^k f_{kj} \\
&amp;= \underbrace{(f_{00} + f_{01} + ... + f_{0k})}_{k \,\text{terms}} + \underbrace{(f_{10} + f_{11} + ... + f_{1k})}_{k \,\text{terms}} + ... + \underbrace{(f_{k0} + f_{k1} + ... + f_{kk})}_{k \,\text{terms}}
&amp; k \,\text{times} \\
&amp;= \text{T} + \text{F} \\
&amp;= \text{N}
&amp; k^2 \,\text{terms}\\
\end{align}
\)</span>$</p>
<div class="section" id="id1">
<h3>Evaluation Measures<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p><strong>Accuracy</strong> <span class="math notranslate nohighlight">\(a\)</span><br>
$<span class="math notranslate nohighlight">\(
\begin{align}
a
&amp;= \frac{\sum_{i = j} f_{ij}}{\sum f_{ij}} \\
&amp;= \frac{f_{00} + f_{11} + ... + f_{kk}}{(f_{00} + f_{01} + ... + f_{0k}) + (f_{10} + f_{11} + ... + f_{1k}) + ... + (f_{k0} + f_{k1} + ... + f_{kk})} \\
&amp;= \frac{\text{T}}{\text{N}} \\
\end{align}
\)</span>$</p>
<p><strong>Error Rate</strong> <span class="math notranslate nohighlight">\(e\)</span><br>
$<span class="math notranslate nohighlight">\(
\begin{align}
e
&amp;= 1 - a \\
&amp;= \frac{\sum_{i \ne j} f_{ij}}{\sum f_{ij}} \\
&amp;= \frac{\underbrace{(f_{01} + f_{02} + ... + f_{0k})}_{k - 1 \,\text{terms}} + \underbrace{(f_{10} + f_{12} + ... + f_{1k})}_{k - 1 \,\text{terms}} + ... + \underbrace{(f_{k0} + f_{k1} + ... + f_{k, k - 1})}_{k - 1 \,\text{terms}}}{\underbrace{(f_{00} + f_{01} + ... + f_{0k})}_{k \,\text{terms}} + \underbrace{(f_{10} + f_{11} + ... + f_{1k})}_{k \,\text{terms}} + ... + \underbrace{(f_{k0} + f_{k1} + ... + f_{kk})}_{k \,\text{terms}}} \\
&amp;= \frac{\text{F}}{\text{N}} \\
\end{align}
\)</span>$</p>
<hr class="docutils" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f00</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">f01</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">f02</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">f10</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">f11</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">f12</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">f20</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">f21</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">f22</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">T</span>  <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">f00</span> <span class="o">+</span> <span class="n">f11</span> <span class="o">+</span> <span class="n">f22</span><span class="p">)</span> <span class="c1"># correct</span>
<span class="n">F</span>  <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">f01</span> <span class="o">+</span> <span class="n">f02</span> <span class="o">+</span> <span class="n">f10</span> <span class="o">+</span> <span class="n">f12</span> <span class="o">+</span> <span class="n">f20</span> <span class="o">+</span> <span class="n">f21</span><span class="p">)</span> <span class="c1"># incorrect</span>
<span class="n">A0</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">f00</span> <span class="o">+</span> <span class="n">f01</span> <span class="o">+</span> <span class="n">f02</span><span class="p">)</span> <span class="c1"># actual class 0</span>
<span class="n">A1</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">f10</span> <span class="o">+</span> <span class="n">f11</span> <span class="o">+</span> <span class="n">f12</span><span class="p">)</span> <span class="c1"># actual class 1</span>
<span class="n">A2</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">f20</span> <span class="o">+</span> <span class="n">f21</span> <span class="o">+</span> <span class="n">f22</span><span class="p">)</span> <span class="c1"># actual class 2</span>

<span class="n">P0</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">f00</span> <span class="o">+</span> <span class="n">f10</span> <span class="o">+</span> <span class="n">f20</span><span class="p">)</span> <span class="c1"># predicted class 0</span>
<span class="n">P1</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">f01</span> <span class="o">+</span> <span class="n">f11</span> <span class="o">+</span> <span class="n">f21</span><span class="p">)</span> <span class="c1"># predicted class 1</span>
<span class="n">P2</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">f02</span> <span class="o">+</span> <span class="n">f12</span> <span class="o">+</span> <span class="n">f22</span><span class="p">)</span> <span class="c1"># predicted class 2</span>

<span class="n">N</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">A0</span> <span class="o">+</span> <span class="n">A1</span> <span class="o">+</span> <span class="n">A2</span><span class="p">)</span> <span class="c1"># all</span>

<span class="n">alpha0</span> <span class="o">=</span> <span class="n">A0</span> <span class="o">/</span> <span class="n">N</span>
<span class="n">alpha1</span> <span class="o">=</span> <span class="n">A1</span> <span class="o">/</span> <span class="n">N</span>
<span class="n">alpha2</span> <span class="o">=</span> <span class="n">A2</span> <span class="o">/</span> <span class="n">N</span>

<span class="n">accuracy</span>             <span class="o">=</span> <span class="n">T</span> <span class="o">/</span> <span class="n">N</span>   <span class="c1"># correct over all</span>
<span class="n">error_rate</span>           <span class="o">=</span> <span class="n">F</span> <span class="o">/</span> <span class="n">N</span>   <span class="c1"># incorrect over all</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">precision            = TP / PP # correct positive over all positive</span>
<span class="sd">false_discovery_rate = FP / PP # incorrect positive over all positive</span>

<span class="sd">true_positive_rate   = TP / AP # correct positive over actual positive</span>
<span class="sd">false_negative_rate  = FN / AP # incorrect negative over actual positive</span>
<span class="sd">true_negative_rate   = TN / AN # correct negative over actual negative</span>
<span class="sd">false_positive_rate  = FP / AN # incorrect positive over actual negative</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="n">lines</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;P0&#39;</span><span class="p">,</span> <span class="s1">&#39;P1&#39;</span><span class="p">,</span> <span class="s1">&#39;P2&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">),</span>
    <span class="s1">&#39;</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;A0&#39;</span><span class="p">,</span> <span class="n">f00</span><span class="p">,</span> <span class="n">f01</span><span class="p">,</span> <span class="n">f02</span><span class="p">,</span> <span class="n">A0</span><span class="p">),</span>
    <span class="s1">&#39;</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;A1&#39;</span><span class="p">,</span> <span class="n">f10</span><span class="p">,</span> <span class="n">f11</span><span class="p">,</span> <span class="n">f12</span><span class="p">,</span> <span class="n">A1</span><span class="p">),</span>
    <span class="s1">&#39;</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;A2&#39;</span><span class="p">,</span> <span class="n">f20</span><span class="p">,</span> <span class="n">f21</span><span class="p">,</span> <span class="n">f22</span><span class="p">,</span> <span class="n">A2</span><span class="p">),</span>
    <span class="s1">&#39;</span><span class="se">\t\t\t\t</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">N</span><span class="p">),</span>
    <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="s1">&#39;</span><span class="si">{:5}{:0.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\u03b1</span><span class="s1">0&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">alpha0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
    <span class="s1">&#39;</span><span class="si">{:5}{:0.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\u03b1</span><span class="s1">1&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">alpha1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
    <span class="s1">&#39;</span><span class="si">{:5}{:0.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\u03b1</span><span class="s1">2&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">alpha2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
    <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="s1">&#39;</span><span class="si">{:5}{:0.3f}</span><span class="se">\t</span><span class="si">{:5}{:0.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">accuracy</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s1">&#39;e&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">error_rate</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
<span class="p">]</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>	P0	P1	P2	
A0	200	5	5	210
A1	5	100	5	110
A2	5	5	100	110
				430

α0   0.488
α1   0.256
α2   0.256

a    0.930	e    0.070
</pre></div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="bayesian-classification">
<h3>Bayesian Classification<a class="headerlink" href="#bayesian-classification" title="Permalink to this headline">¶</a></h3>
<p><strong>Posterior Probability of the target class</strong><br>
compute the probability of observing a class label <span class="math notranslate nohighlight">\(y\)</span> for a data instance given its set of attribute values <span class="math notranslate nohighlight">\(\textbf{x}\)</span><br>
$<span class="math notranslate nohighlight">\(P(y | \textbf{x}) = \frac{P(\textbf{x} | y)P(y)}{P(\textbf{x})}\)</span>$</p>
<p><strong>Class-Conditional Probability of the attributes given the class label <span class="math notranslate nohighlight">\(P(\textbf{x} | y)\)</span></strong><br>
measures the likelihood of observing <span class="math notranslate nohighlight">\(\textbf{x}\)</span> from the distribution of instances belonging to <span class="math notranslate nohighlight">\(y\)</span><br>
describes the behavior of instances in the attribute space that are <em>generated</em> from class <span class="math notranslate nohighlight">\(y\)</span><br>
if <span class="math notranslate nohighlight">\(\textbf{x}\)</span> indeed belongs to class <span class="math notranslate nohighlight">\(y\)</span>, then we should expect <span class="math notranslate nohighlight">\(P(\textbf{x} | y)\)</span> to be high<br>
the use of class-conditional probabilities attempts to capture the process from which the data instances were generated<br>
provide insights about the underlying mechanism behind the generation of attribute values<br></p>
<p><strong>Prior Probability <span class="math notranslate nohighlight">\(P(y)\)</span></strong><br>
captures our prior beliefs about the distribution of class labels, independent of the observed attribute values<br>
can either be obtained using expert knowledge, or inferred from historical distribution of class labels<br></p>
<p>combine one’s prior beliefs with the likelihood of obtaining the observed attribute values<br>
Training: learn the parameters for <span class="math notranslate nohighlight">\(P(y)\)</span> and <span class="math notranslate nohighlight">\(P(\textbf{x} | y)\)</span><br>
<span class="math notranslate nohighlight">\(P(y)\)</span> is easily estimated from the training set by computing the fraction of training instances that belong to each class<br></p>
<p><strong>Class-Conditional Probability Estimation</strong><br>
<span class="math notranslate nohighlight">\(P(\textbf{x} | y)\)</span> is estimated by considering the fraction of training instances of a given class for every possible combination of attribute values:<br>
Let <span class="math notranslate nohighlight">\(X_1\)</span> and <span class="math notranslate nohighlight">\(X_2\)</span> be two attributes each of which can take a discrete value from <span class="math notranslate nohighlight">\(c_1\)</span> to <span class="math notranslate nohighlight">\(c_k\)</span><br>
Let <span class="math notranslate nohighlight">\(n^0\)</span> denote the number of training instances belonging to class <span class="math notranslate nohighlight">\(0\)</span>, out of which <span class="math notranslate nohighlight">\(n_{ij}^0\)</span> number of training instances have <span class="math notranslate nohighlight">\(X_1 = c_i\)</span> and <span class="math notranslate nohighlight">\(X_2 = c_j\)</span><br>
$<span class="math notranslate nohighlight">\(P(X_1 = c_i, X_2 = c_j | Y = 0) = \frac{n_{ij}^0}{n^0}\)</span>$</p>
</div>
<hr class="docutils" />
<div class="section" id="naive-bayes-classifier">
<h3>Naive Bayes Classifier<a class="headerlink" href="#naive-bayes-classifier" title="Permalink to this headline">¶</a></h3>
<p><strong>Naive Bayes Assumption</strong><br>
the class-conditional probability of all attributes <span class="math notranslate nohighlight">\(\textbf{x}\)</span> can be factored as a product of class-conditional probabilities of every attribute <span class="math notranslate nohighlight">\(x_i\)</span>:
$<span class="math notranslate nohighlight">\(P(\textbf{x} | y) = \prod_{i = 1}^d P(x_i | y)\)</span><span class="math notranslate nohighlight">\(
where every data instance \)</span>\textbf{x}<span class="math notranslate nohighlight">\( consists of \)</span>d<span class="math notranslate nohighlight">\( attributes \)</span>{x_1, …, x_d}<span class="math notranslate nohighlight">\(&lt;br&gt;
assumption: the attribute values \)</span>x_i<span class="math notranslate nohighlight">\( are conditionally independent of each other, given the class label \)</span>y$ (this means that the attributes are influenced only by the target class and if we know the class label, then we can consider the attributes to be independent of each other)<br></p>
<p>given the naive Bayes assumption, we only need to estimate the conditional probability of each <span class="math notranslate nohighlight">\(x_i\)</span> given <span class="math notranslate nohighlight">\(Y\)</span> separately, instead of computing the class-conditional probability for every combination of attribute values<br></p>
<p><strong>Class-Conditional Probability Estimation under the Naive Bayes Assumption</strong><br>
count the number of training instances for every one of the <span class="math notranslate nohighlight">\(k\)</span> values of an attribute <span class="math notranslate nohighlight">\(X\)</span> irrespective of the values of other attributes<br>
the number of parameters needed to learn class-conditional probabilities is <span class="math notranslate nohighlight">\(dk\)</span>, linear in the number of attributes<br>
$<span class="math notranslate nohighlight">\(P(X_1 = c_i, X_2 = c_j | Y = 0) = \frac{n_i^0}{n^0} \times \frac{n_j^0}{n^0}\)</span>$</p>
<p><strong>Naive Bayes Classifier</strong><br>
computes the posterior probability for a test instance <span class="math notranslate nohighlight">\(\textbf{x}\)</span>:
$<span class="math notranslate nohighlight">\(
\begin{align}
P(y | \textbf{x}) &amp;= \frac{P(y) \prod_{i = 1}^d P(x_i | y)}{P(\textbf{x})} \\
P(y | \textbf{x}) &amp;\propto P(y) \prod_{i = 1}^d P(x_i | y) \\
\end{align}
\)</span>$</p>
<p><strong>Categorical Attribute Conditional Probability Estimation</strong><br>
Let <span class="math notranslate nohighlight">\(X_i\)</span> be a categorical attribute.<br>
The conditional probability <span class="math notranslate nohighlight">\(P(X_i = c | y)\)</span> is estimated according to the fraction of training instances in class <span class="math notranslate nohighlight">\(y\)</span> where <span class="math notranslate nohighlight">\(X_i\)</span> takes on a particular categorical value <span class="math notranslate nohighlight">\(c\)</span>:<br>
<span class="math notranslate nohighlight">\(n\)</span> is the number of training instances belonging to class <span class="math notranslate nohighlight">\(y\)</span> out of which <span class="math notranslate nohighlight">\(n_c\)</span> number of instances have <span class="math notranslate nohighlight">\(X_i = c\)</span><br>
<span class="math notranslate nohighlight">\(\sum_c P(X_i = c | y) = 1\)</span><br>
$<span class="math notranslate nohighlight">\(P(X_i = c | y) = \frac{n_c}{n}\)</span>$</p>
<hr class="docutils" />
<hr class="docutils" />
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="statistics">
<h1>Statistics<a class="headerlink" href="#statistics" title="Permalink to this headline">¶</a></h1>
<div class="section" id="frequency-distribution-vs-relative-frequency-distribution">
<h2>Frequency Distribution vs Relative Frequency Distribution<a class="headerlink" href="#frequency-distribution-vs-relative-frequency-distribution" title="Permalink to this headline">¶</a></h2>
<p>Frequency, the number of observations that fall into a category <br>
Relative Frequency, the proportion or percentage in a category (the count in a category relative to the total count over all categories) <br>
Frequency Distribution for a categorical variable, a listing of all categories along with their frequencies/counts <br>
Relative Frequency Distribution, a listing of all categories along with their relative frequencies (given as proportions or percentages) <br></p>
</div>
<div class="section" id="clt-central-limit-theorem">
<h2>CLT Central Limit Theorem<a class="headerlink" href="#clt-central-limit-theorem" title="Permalink to this headline">¶</a></h2>
<p>CLT ensures that the majority of “scattered things” are dispersed according to the Gaussian distribution.</p>
</div>
<div class="section" id="standard-deviation">
<h2>Standard Deviation<a class="headerlink" href="#standard-deviation" title="Permalink to this headline">¶</a></h2>
<p>Roughly, the average distance values fall from the mean.</p>
</div>
<div class="section" id="standardized-z-score">
<h2>Standardized z-Score<a class="headerlink" href="#standardized-z-score" title="Permalink to this headline">¶</a></h2>
<p>a useful measure of the relative value of any observation in a dataset. <br>
the distance between the observed value and the mean, measured in terms of number of standard deviations. <br></p>
</div>
<div class="section" id="ppmcc-pearson-s-product-moment-correlation-coefficient">
<h2>PPMCC Pearson’s Product-Moment Correlation Coefficient<a class="headerlink" href="#ppmcc-pearson-s-product-moment-correlation-coefficient" title="Permalink to this headline">¶</a></h2>
<p>a measure of the strength and direction of a linear relationship between two quantitative variables <br>
approximately, the correlation value is the average product pf standardized scores for variables x and y <br></p>
</div>
<div class="section" id="regression-analysis-and-the-estimation-of-a-regression-equation">
<h2>Regression Analysis and the Estimation of a Regression Equation<a class="headerlink" href="#regression-analysis-and-the-estimation-of-a-regression-equation" title="Permalink to this headline">¶</a></h2>
<p>an equation that describes the average relationship between a quantitative response variable and one or more explanatory variables <br></p>
<p>Least Squares (Least Sum of Squared Errors) <br>
the sum of squared differences between the observed values of y and the predicted values is smaller for that line that it is for any other line (the least squares line minimizes the sum of squared prediction errors for the observed data set) <br></p>
<p>    
<span class="math notranslate nohighlight">\(\hat{y}\)</span>, called the estimated or predicted <span class="math notranslate nohighlight">\(y\)</span>, estimates the average (or predicts) <span class="math notranslate nohighlight">\(y\)</span> for a specific value of <span class="math notranslate nohighlight">\(x\)</span> <br>
    
the slope of the line estimates the average increase in <span class="math notranslate nohighlight">\(y\)</span> for each one-unit increase in <span class="math notranslate nohighlight">\(x\)</span> <br></p>
</div>
<div class="section" id="gaussian-distribution">
<h2>Gaussian Distribution<a class="headerlink" href="#gaussian-distribution" title="Permalink to this headline">¶</a></h2>
<p><span class="math notranslate nohighlight">\(f(x; \mu, \sigma) = \frac{1}{\sigma^2 \sqrt{2\pi}} e^{\frac{-(x - \mu)^2}{2 \sigma^2}}\)</span> where <span class="math notranslate nohighlight">\(\mu\)</span> is the mean and <span class="math notranslate nohighlight">\(\sigma\)</span> is the the standard deviation <br></p>
<div class="section" id="empirical-rule-for-normally-distributed-data">
<h3>Empirical Rule for normally-distributed data<a class="headerlink" href="#empirical-rule-for-normally-distributed-data" title="Permalink to this headline">¶</a></h3>
<p>About 68% of the values have z-scores <span class="math notranslate nohighlight">\(\in [-1, 1]\)</span> <br>
About 95% of the values have z-scores <span class="math notranslate nohighlight">\(\in [-2, 2]\)</span> <br>
About 99.7% of the values have z-scores <span class="math notranslate nohighlight">\(\in [-3, 3]\)</span> <br></p>
</div>
</div>
<div class="section" id="standard-normal-distribution">
<h2>Standard Normal Distribution<a class="headerlink" href="#standard-normal-distribution" title="Permalink to this headline">¶</a></h2>
<p><span class="math notranslate nohighlight">\(f(x; 0, 1) = \frac{1}{\sqrt{2\pi}} e^{\frac{-x^2}{2}}\)</span> where <span class="math notranslate nohighlight">\(\mu = 0\)</span> and <span class="math notranslate nohighlight">\(\sigma = 1\)</span></p>
<hr class="docutils" />
<hr class="docutils" />
</div>
</div>
<hr class="docutils" />
<div class="section" id="probability-theory">
<h1>Probability Theory<a class="headerlink" href="#probability-theory" title="Permalink to this headline">¶</a></h1>
<p>Let <span class="math notranslate nohighlight">\(X\)</span> be a variable that can take any discrete value from the set <span class="math notranslate nohighlight">\(\{x_1, ..., x_k\}\)</span><br></p>
<p><strong>Random Variable</strong><br>
a variable that has probabilities associated with each possible outcome/value<br></p>
<p><strong>Relative Frequency</strong><br>
If <span class="math notranslate nohighlight">\(X\)</span> has the value <span class="math notranslate nohighlight">\(x_i\)</span> for <span class="math notranslate nohighlight">\(n_i\)</span> data objects, then the relative frequency with which we observe the event <span class="math notranslate nohighlight">\(X = x_i\)</span> is <span class="math notranslate nohighlight">\(\frac{n_i}{N}\)</span> where <span class="math notranslate nohighlight">\(N = \sum_{i = 1}^k n_i\)</span> is the total number of data objects (i.e., the size of the dataset).<br></p>
<p><strong>Probability</strong><br>
The probability of an event <span class="math notranslate nohighlight">\(e\)</span> (e.g., <span class="math notranslate nohighlight">\(P(X = x_i)\)</span>) measures how likely it is for the event <span class="math notranslate nohighlight">\(e\)</span> to occur.<br>
The frequentist approach to probability is based on the relative frequency of events.<br></p>
<p><strong>Axioms of Probability Theory</strong><br>
$$
\begin{align}</p>
<ol class="simple">
<li><p>&amp; P \in [0, 1] \</p></li>
<li><p>&amp; \sum_i P(X = x_i) = 1 \
\end{align}
$$</p></li>
</ol>
<p><strong>Joint Probability</strong><br>
Let <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> be two random variables that can each take <span class="math notranslate nohighlight">\(k\)</span> discrete values.<br>
Let <span class="math notranslate nohighlight">\(n_{ij}\)</span> be the number of times we observe <span class="math notranslate nohighlight">\(X = x_i\)</span> and <span class="math notranslate nohighlight">\(Y = y_j\)</span> out of a total number of <span class="math notranslate nohighlight">\(N\)</span> occurrences.<br>
$<span class="math notranslate nohighlight">\(P(X = x_i, Y = y_i) = \frac{n_{ij}}{N}\)</span><span class="math notranslate nohighlight">\(
Symmetry of Joint Probability: \)</span>P(X = x_i, Y = y_i) = P( Y = y_i, X = x_i)$</p>
<p><strong>Marginal Probability of</strong> <span class="math notranslate nohighlight">\(X\)</span><br>
$<span class="math notranslate nohighlight">\(\sum_{j = 1}^k P(X = x_i, Y = y_j) = \frac{\sum_{j = 1}^k n_{ij}}{N} = \frac{n_i}{N} = P(X = x_i)\)</span><span class="math notranslate nohighlight">\(
where \)</span>n_i<span class="math notranslate nohighlight">\( is the total number of times we observe \)</span>X = x_i<span class="math notranslate nohighlight">\( irrespective of the value of \)</span>Y<span class="math notranslate nohighlight">\( and
\)</span>\frac{n_i}{N}<span class="math notranslate nohighlight">\( is the probability of observing the remaining variable \)</span>X$<br></p>
<p><strong>Conditional Probability</strong><br>
Let <span class="math notranslate nohighlight">\(P(Y | X)\)</span> be the conditional probability of observing the random variable <span class="math notranslate nohighlight">\(Y\)</span> whenever the random variable <span class="math notranslate nohighlight">\(X\)</span> takes a particular value (the probability of observing <span class="math notranslate nohighlight">\(Y\)</span> conditioned on the outcome of <span class="math notranslate nohighlight">\(X\)</span>).<br>
$<span class="math notranslate nohighlight">\(
\begin{align}
P(Y | X) &amp;= \frac{P(X, Y)}{P(X)} \\
P(X, Y) &amp;= P(Y | X) \times P(X) \\
&amp;= P(X | Y) \times P(Y) \\
\end{align}
\)</span>$</p>
<p><strong>Bayes Theorem</strong><br>
relates the conditional probabilities <span class="math notranslate nohighlight">\(P(Y | X)\)</span> and <span class="math notranslate nohighlight">\(P(X | Y)\)</span><br>
Likelihood <span class="math notranslate nohighlight">\(P(X | Y)\)</span><br>
Prior <span class="math notranslate nohighlight">\(P(Y)\)</span><br>
Posterior <span class="math notranslate nohighlight">\(P(Y | X)\)</span><br>
Normalization Constant or Probability of Evidence <span class="math notranslate nohighlight">\(P(X)\)</span> (the marginal probability of <span class="math notranslate nohighlight">\(X\)</span>)<br>
$<span class="math notranslate nohighlight">\(
\begin{align}
P(Y | X) &amp;= \frac{P(X | Y)P(Y)}{P(X)} \\
&amp;= \frac{P(X | Y)P(Y)}{\sum_{i = 1}^k P(X, y_i)} \\
&amp;= \frac{P(X | Y)P(Y)}{\sum_{i = 1}^k P(X | y_i)P(y_i)} \\
\end{align}
\)</span>$</p>
<p><strong>Conditional Independence</strong><br>
Let <span class="math notranslate nohighlight">\(\textbf{X}_1\)</span>, <span class="math notranslate nohighlight">\(\textbf{X}_2\)</span>, and <span class="math notranslate nohighlight">\(\textbf{Y}\)</span> be three sets of random variables.<br>
The variables in <span class="math notranslate nohighlight">\(\textbf{X}_1\)</span> are conditionally independent of <span class="math notranslate nohighlight">\(\textbf{X}_2\)</span>, given <span class="math notranslate nohighlight">\(\textbf{Y}\)</span>, if:<br>
$<span class="math notranslate nohighlight">\(P(\textbf{X}_1 | \textbf{X}_2, \textbf{Y}) = P(\textbf{X}_1 | \textbf{Y})\)</span>$</p>
<p><strong>Joint Conditional Probability</strong><br>
$<span class="math notranslate nohighlight">\(
\begin{align}
P(\textbf{X}_1, \textbf{X}_2 | \textbf{Y}) &amp;= \frac{P(\textbf{X}_1, \textbf{X}_2, \textbf{Y})}{P(\textbf{Y})} \\
&amp;= \frac{P(\textbf{X}_1, \textbf{X}_2, \textbf{Y})}{P(\textbf{X}_2, \textbf{Y})} \times \frac{P(\textbf{X}_2, \textbf{Y})}{P(\textbf{Y})} \\
&amp;= P(\textbf{X}_1 | \textbf{X}_2, \textbf{Y}) \times P(\textbf{X}_2 | \textbf{Y}) \\
&amp;= P(\textbf{X}_1 | \textbf{Y}) \times P(\textbf{X}_2 | \textbf{Y}) \\
\end{align}
\)</span>$</p>
<hr class="docutils" />
<hr class="docutils" />
</div>
<hr class="docutils" />
<div class="section" id="stochastic-processes-and-time-series">
<h1>Stochastic Processes and Time Series<a class="headerlink" href="#stochastic-processes-and-time-series" title="Permalink to this headline">¶</a></h1>
<hr class="docutils" />
<p><strong>Stochastic Methods</strong><br>
Branching Processes<br>
Conditioning<br>
Counting Paths<br>
Difference Equations<br>
Generating Functions<br>
Markov Chains<br>
Martingales<br>
Mirroring<br>
Random Walk Analysis<br>
Time Reversal<br></p>
<hr class="docutils" />
<div class="section" id="random-walk">
<h2>Random Walk<a class="headerlink" href="#random-walk" title="Permalink to this headline">¶</a></h2>
<p><strong>Random Walk</strong> is a mathematical object; namely, it is a stochastic sequence <span class="math notranslate nohighlight">\(\{S_n\}\)</span> on some mathematical space, where <span class="math notranslate nohighlight">\(\{X_k\}\)</span> are iid independent and identically distributed random variables.<br>
$<span class="math notranslate nohighlight">\(S_n = \sum_{k = 1}^n X_k \,\text{with}\, S_0 = 0\)</span>$</p>
<p>The random walk is <em>simple</em> if <span class="math notranslate nohighlight">\(X_k = \pm 1\)</span> with <span class="math notranslate nohighlight">\(P(X_k = 1) = p\)</span> and <span class="math notranslate nohighlight">\(P(X_k = -1) = 1 - p = q\)</span><br></p>
<p>A simple random walk is <em>symmetric</em> if the particle has the same probability for each of the neighboring points<br></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this is a symmetric simple random walk over Z^2</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">mu</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">mu</span>
<span class="n">i</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">x</span><span class="p">[</span><span class="n">t</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">x</span><span class="p">[</span><span class="n">t</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">i</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">x</span><span class="p">[</span><span class="n">t</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">x</span><span class="p">[</span><span class="n">t</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">i</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="n">x</span><span class="p">[</span><span class="n">t</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">x</span><span class="p">[</span><span class="n">t</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">elif</span> <span class="n">i</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
        <span class="n">x</span><span class="p">[</span><span class="n">t</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">x</span><span class="p">[</span><span class="n">t</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_158_0.png" src="../_images/mathematical_foundations_158_0.png" />
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="arima-0-1-0">
<h1>ARIMA(0, 1, 0)<a class="headerlink" href="#arima-0-1-0" title="Permalink to this headline">¶</a></h1>
<p>ARIMA(0, 1, 0), or I(1), is just a random walk<br>
$<span class="math notranslate nohighlight">\(y_t = \mu + y_{t - 1} + \epsilon_t\)</span>$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">npr</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># uncomment for deterministic output; comment for random output</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">wn</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">mu</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">mu</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">y</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">wn</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_161_0.png" src="../_images/mathematical_foundations_161_0.png" />
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="arima-0-0-1">
<h1>ARIMA(0, 0, 1)<a class="headerlink" href="#arima-0-0-1" title="Permalink to this headline">¶</a></h1>
<p>ARIMA(0, 0, 1) is just Moving Average MA(1)<br>
$<span class="math notranslate nohighlight">\(\hat{y_t} = \mu + \theta_1\epsilon_{t - 1}\)</span><span class="math notranslate nohighlight">\(
\)</span><span class="math notranslate nohighlight">\(y_t = \mu + \epsilon_t + \theta_1\epsilon_{t - 1}\)</span>$</p>
<p><strong>MA(q) = ARIMA(0, 0, q)</strong><br>
$<span class="math notranslate nohighlight">\(\hat{y_t} = \mu + \theta_1\epsilon_{t - 1} + ... + \theta_q\epsilon_{t - q}\)</span><span class="math notranslate nohighlight">\(
\)</span><span class="math notranslate nohighlight">\(y_t = \mu + \epsilon_t + \theta_1\epsilon_{t - 1} + ... + \theta_q\epsilon_{t - q}\)</span>$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">npr</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># uncomment for deterministic output; comment for random output</span>

<span class="n">n</span>     <span class="o">=</span> <span class="mi">1000</span>
<span class="n">wn</span>    <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># white noise error terms</span>
<span class="n">mu</span>    <span class="o">=</span> <span class="mi">10</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span>  <span class="c1"># weights</span>
<span class="n">x</span>     <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">y</span>     <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="o">=</span> <span class="n">mu</span>

<span class="n">y2</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">mu</span>

<span class="n">y3</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y3</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">mu</span>

<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">y</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">wn</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">theta</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span> <span class="n">wn</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">y2</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">wn</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">theta</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="n">wn</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="n">wn</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">2</span><span class="p">]])</span>
    <span class="n">y3</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">wn</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">theta</span><span class="p">[:</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="n">wn</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="n">wn</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">2</span><span class="p">],</span> <span class="n">wn</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">3</span><span class="p">]])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y3</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_164_0.png" src="../_images/mathematical_foundations_164_0.png" />
</div>
</div>
<hr class="docutils" />
<p><strong>Rolling Statistics</strong><br>
SMA Simple Moving Average<br>
Central Moving Average<br>
CMA Cumulative Moving Average<br>
EWMA Exponentially-Weighted Moving Average<br>
Standard Deviation<br></p>
<p><strong>Correlation</strong><br>
<strong>Cross Correlation</strong><br>
<strong>ACF Autocorrelation</strong> and <strong>PACF Partial Autocorrelation</strong><br>
a measure of how closely current values are correlated with past values<br></p>
<p><strong>Decomposition</strong> (trend, periodicity, noise)<br>
<strong>Hodrick-Prescott Filter</strong><br>
$<span class="math notranslate nohighlight">\(\text{min}_{\tau} \left( \sum_{t=1}^T (y_t - \tau_t)^2 + \lambda \sum_{t=2}^{T-1} [(\tau_{t+1} - \tau_t) - (\tau_t - \tau_{t-1})^2] \right)\)</span>$</p>
<p><strong>AR Autoregression</strong><br>
<strong>MA Moving-Average Model</strong><br>
<strong>ARIMA Autoregressive Integrated Moving Average</strong><br>
<strong>ARMA Autoregessive Moving Average</strong><br>
predict future valies on the basis of past values and past errors<br>
assumes stationarity<br>
assumes non stationarity<br>
<strong>GARCH Generalized Autoregressive Conditional Heteroskedasticity</strong><br></p>
</div>
<div class="section" id="sma-k-simple-moving-average-wiki-br-dataset-x-1-x-n-br-window-k-br-text-sma-k">
<h1><strong>SMA<span class="math notranslate nohighlight">\(_k\)</span> Simple Moving Average</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/Moving_average#Simple_moving_average_(boxcar_filter)">Wiki</a><br>
dataset <span class="math notranslate nohighlight">\(= \{x_1, ..., x_n\}\)</span><br>
window <span class="math notranslate nohighlight">\(k\)</span><br>
$$
\text{SMA}_k<a class="headerlink" href="#sma-k-simple-moving-average-wiki-br-dataset-x-1-x-n-br-window-k-br-text-sma-k" title="Permalink to this headline">¶</a></h1>
</div>
<div class="section" id="frac-x-n-k-1-x-n-k-2-x-n-k">
<h1>\frac{x_{n - k + 1} + x_{n - k + 2} + … + x_n}{k}<a class="headerlink" href="#frac-x-n-k-1-x-n-k-2-x-n-k" title="Permalink to this headline">¶</a></h1>
<p>\frac{1}{k} \sum_{i = n - k + 1}^{n} x_i
$$</p>
<div class="math notranslate nohighlight">
\[
SMA_{k, next}
=
\frac{1}{k} \sum_{i = n - k + 2}^{n + 1} x_i
=
\frac{1}{k} (\underbrace{x_{n - k + 2} + x_{n - k + 3} + ... + x_n + x_{n + 1}}_{= \sum_{i = n - k + 2}^{n + 1} x_i} + \underbrace{x_{n - k + 1} - x_{n - k + 1}}_{= 0})
=
\underbrace{\frac{1}{k} (x_{n - k + 1} + x_{n - k + 2} + ... + x_n)}_{= \text{SMA}_{k, prev}} - \frac{x_{n - k + 1}}{k} + \frac{x_{n + 1}}{k}
=
\text{SMA}_{k, prev} + \frac{1}{k} (x_{n + 1} - x_{n - k + 1})
\]</div>
<p><strong>CMA Cumulative Moving Average</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/Moving_average#Cumulative_moving_average">Wiki</a><br>
$<span class="math notranslate nohighlight">\(\text{CMA}_n = \frac{x_1 + ... + x_n}{n}\)</span><span class="math notranslate nohighlight">\(
\)</span><span class="math notranslate nohighlight">\(\text{CMA}_{n + 1} = \frac{x_{n + 1} + n\text{CMA}_n}{n + 1}\)</span>$</p>
<hr class="docutils" />
<hr class="docutils" />
</div>
<hr class="docutils" />
<div class="section" id="dsp-digital-signal-processing-and-filters">
<h1>DSP Digital Signal Processing and Filters<a class="headerlink" href="#dsp-digital-signal-processing-and-filters" title="Permalink to this headline">¶</a></h1>
<hr class="docutils" />
<p><strong>SMA Simple Moving Average FIR Finite Impulse Response Filter</strong><br>
$<span class="math notranslate nohighlight">\(y[n] = \frac{1}{L} \sum_{k = 0}^{L - 1} x[n - k]\)</span>$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># a simple moving average filter implemented in NumPy</span>
<span class="c1"># the signal must be padded with a sufficient number 0s (i.e., &quot;no signal&quot;) on either side of the signal</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># signal size</span>
<span class="n">w</span> <span class="o">=</span> <span class="mi">5</span>  <span class="c1"># window size</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">w</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">w</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">w</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">w</span><span class="p">)])</span>

<span class="n">roll_avg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">w</span><span class="p">),</span> <span class="s1">&#39;valid&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="n">w</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">w</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:],</span> <span class="n">roll_avg</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">w</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:],</span> <span class="n">np</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">roll_avg</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_172_0.png" src="../_images/mathematical_foundations_172_0.png" />
</div>
</div>
<hr class="docutils" />
<p>experimenting with complex periodic sinusoidal waves</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A1</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">f1</span> <span class="o">=</span> <span class="mf">1e2</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mi">1001</span><span class="p">)</span>
<span class="n">y1</span> <span class="o">=</span> <span class="n">A1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">f1</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span>
<span class="n">A2</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">f2</span> <span class="o">=</span> <span class="mf">1e3</span>
<span class="n">y2</span> <span class="o">=</span> <span class="n">A2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">f2</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">y1</span> <span class="o">+</span> <span class="n">y2</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_175_0.png" src="../_images/mathematical_foundations_175_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mi">1001</span><span class="p">)</span>

<span class="n">A1</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">f1</span> <span class="o">=</span> <span class="mf">4e2</span>
<span class="n">y1</span> <span class="o">=</span> <span class="n">A1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">f1</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span>

<span class="n">A2</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">f2</span> <span class="o">=</span> <span class="mf">5e2</span>
<span class="n">y2</span> <span class="o">=</span> <span class="n">A2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">f2</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">y1</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">y2</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">y1</span> <span class="o">+</span> <span class="n">y2</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_176_0.png" src="../_images/mathematical_foundations_176_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mi">1001</span><span class="p">)</span>

<span class="n">A1</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">f1</span> <span class="o">=</span> <span class="mf">1e2</span>
<span class="n">y1</span> <span class="o">=</span> <span class="n">A1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">f1</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span>

<span class="n">A2</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">f2</span> <span class="o">=</span> <span class="mf">2e2</span>
<span class="n">y2</span> <span class="o">=</span> <span class="n">A2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">f2</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span>

<span class="n">A3</span> <span class="o">=</span> <span class="mf">0.33</span>
<span class="n">f3</span> <span class="o">=</span> <span class="mf">3e2</span>
<span class="n">y3</span> <span class="o">=</span> <span class="n">A3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">f3</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span>

<span class="n">A4</span> <span class="o">=</span> <span class="mf">0.25</span>
<span class="n">f4</span> <span class="o">=</span> <span class="mf">4e2</span>
<span class="n">y4</span> <span class="o">=</span> <span class="n">A4</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">f4</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span>

<span class="n">A5</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">f5</span> <span class="o">=</span> <span class="mf">5e2</span>
<span class="n">y5</span> <span class="o">=</span> <span class="n">A5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">f5</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">6</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">y1</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">y2</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">y3</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">y4</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">y5</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">y1</span> <span class="o">+</span> <span class="n">y2</span> <span class="o">+</span> <span class="n">y3</span> <span class="o">+</span> <span class="n">y4</span> <span class="o">+</span> <span class="n">y5</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_177_0.png" src="../_images/mathematical_foundations_177_0.png" />
</div>
</div>
<hr class="docutils" />
<hr class="docutils" />
</div>
<hr class="docutils" />
<div class="section" id="mathematical-finance">
<h1>Mathematical Finance<a class="headerlink" href="#mathematical-finance" title="Permalink to this headline">¶</a></h1>
<hr class="docutils" />
<p><strong>Annualized Standard Deviation</strong> <span class="math notranslate nohighlight">\(=\)</span> Daily Standard Deviation <span class="math notranslate nohighlight">\(\times \sqrt{252}\)</span><br></p>
<p><strong>NPV Net Present Value</strong><br></p>
<p><strong>Present Discounted Value</strong><br></p>
<p><strong>Sharpe Ratio</strong><br>
<span class="math notranslate nohighlight">\(\frac{R_p - R_f}{\sigma_p} =\)</span> Annualized_Average_Returns <span class="math notranslate nohighlight">\(\times 252\)</span> divided by Annualized_Standard_Deviation <span class="math notranslate nohighlight">\(\times \sqrt{252}\)</span><br></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Rp Portfolio Return
Rf Risk-Free Rate, the return that one expects if investing in securities that effectively offer a guaranteed return (e.g., 30-day U.S. government T-Bills)
</pre></div>
</div>
<hr class="docutils" />
<div class="section" id="tvm-time-value-of-money">
<h2>TVM Time Value of Money<a class="headerlink" href="#tvm-time-value-of-money" title="Permalink to this headline">¶</a></h2>
<p><span class="math notranslate nohighlight">\(FV = PV\left(1 + \frac{i}{n}\right)^{nt}\)</span><br>
<span class="math notranslate nohighlight">\(PV = FV\left(1 + \frac{i}{n}\right)^{-nt}\)</span></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>FV future value of money
PV present value of money
i interest rate
n number of compounding periods per year
t number of years
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calc_fv</span> <span class="p">(</span><span class="n">pv</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Calculate the future value of money.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>
<span class="sd">      pv (float) present value of money</span>
<span class="sd">      i  (float) rate of return</span>
<span class="sd">      n  (int)   number of compounding periods per unit time</span>
<span class="sd">      t  (int)   time</span>
<span class="sd">    Return</span>
<span class="sd">    ======</span>
<span class="sd">      fv (float) future value of money</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">fv</span> <span class="o">=</span> <span class="n">pv</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">ii</span><span class="o">/</span><span class="n">nn</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="n">nn</span><span class="o">*</span><span class="n">t</span><span class="p">)</span>                  <span class="c1"># future value of money</span>
    <span class="k">return</span> <span class="n">fv</span>
<span class="k">def</span> <span class="nf">calc_pv</span> <span class="p">(</span><span class="n">fv</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Calculate the present value of money.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>
<span class="sd">      fv (float) future value of money</span>
<span class="sd">      i  (float) rate of return</span>
<span class="sd">      n  (int)   number of compounding periods per unit time</span>
<span class="sd">      t  (int)   time</span>
<span class="sd">    Return</span>
<span class="sd">    ======</span>
<span class="sd">      pv (float) present value of money</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">pv</span> <span class="o">=</span> <span class="n">fv</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">ii</span><span class="o">/</span><span class="n">nn</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="n">nn</span><span class="o">*</span><span class="n">t</span><span class="p">)</span>                  <span class="c1"># present value of money</span>
    <span class="k">return</span> <span class="n">pv</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pv</span> <span class="o">=</span> <span class="mi">1000</span>                                    <span class="c1"># present value of money</span>
<span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mi">301</span><span class="p">)</span>               <span class="c1"># rates of return</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">52</span><span class="p">,</span> <span class="mi">365</span><span class="p">,</span> <span class="mi">60</span><span class="o">*</span><span class="mi">60</span><span class="o">*</span><span class="mi">24</span><span class="o">*</span><span class="mi">7</span><span class="o">*</span><span class="mi">52</span><span class="p">])</span> <span class="c1"># number of compounding periods</span>
<span class="n">ii</span><span class="p">,</span> <span class="n">nn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">t</span> <span class="o">=</span> <span class="mi">5</span>                                        <span class="c1"># time horizon in years</span>
<span class="n">fv</span> <span class="o">=</span> <span class="n">calc_fv</span><span class="p">(</span><span class="n">pv</span><span class="p">,</span> <span class="n">ii</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">fv</span><span class="p">[:,</span><span class="o">-</span><span class="mi">5</span><span class="p">:],</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[3656.16, 3670.29, 3684.46, 3698.67, 3712.93],
       [4169.52, 4188.97, 4208.51, 4228.14, 4247.85],
       [4374.55, 4396.35, 4418.26, 4440.28, 4462.41],
       [4390.31, 4412.3 , 4434.4 , 4456.61, 4478.93],
       [4392.95, 4414.97, 4437.1 , 4459.34, 4481.69]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ii</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">fv</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ii</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">fv</span><span class="p">[</span><span class="mi">4</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_187_0.png" src="../_images/mathematical_foundations_187_0.png" />
</div>
</div>
<hr class="docutils" />
<hr class="docutils" />
</div>
</div>
<hr class="docutils" />
<div class="section" id="mathematical-functions">
<h1>Mathematical Functions<a class="headerlink" href="#mathematical-functions" title="Permalink to this headline">¶</a></h1>
</div>
<hr class="docutils" />
<div class="section" id="ramp-function-wiki-br-r-x-begin-cases-x-x-ge-0-0-x-lt-0-end-cases">
<h1><strong>Ramp Function</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/Ramp_function">Wiki</a><br>
$$
R(x)=
\begin{cases}
x &amp; x \ge 0 \
0 &amp; x \lt 0 \
\end{cases}<a class="headerlink" href="#ramp-function-wiki-br-r-x-begin-cases-x-x-ge-0-0-x-lt-0-end-cases" title="Permalink to this headline">¶</a></h1>
<p>\text{max}, (x, 0)
$$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4001</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">b</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_192_0.png" src="../_images/mathematical_foundations_192_0.png" />
</div>
</div>
<hr class="docutils" />
<p><strong>Heaviside Step Function</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/Heaviside_step_function">Wiki</a><br>
$<span class="math notranslate nohighlight">\(
H(x)=
\begin{cases}
1 &amp; x \gt 0 \\
0 &amp; x \lt 0 \\
\end{cases}
\)</span>$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4001</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">b</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_195_0.png" src="../_images/mathematical_foundations_195_0.png" />
</div>
</div>
<hr class="docutils" />
<p><strong>Continuous Uniform Distribution</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/Continuous_uniform_distribution">Wiki</a><br>
$<span class="math notranslate nohighlight">\(
f(x)=
\begin{cases}
\frac{1}{b - a} &amp;\text{for}\, a \le x \le b \\
0 &amp;\text{for}\, x \lt a \,\text{or}\, x \gt b \\
\end{cases}
\)</span>$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4001</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">b</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">x</span> <span class="o">&lt;</span> <span class="n">a</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="n">b</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_198_0.png" src="../_images/mathematical_foundations_198_0.png" />
</div>
</div>
<hr class="docutils" />
<p><strong>Boxcar Function</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/Boxcar_function">Wiki</a><br>
any function which is zero over the entire real line, except for a single interval, where it is equal to a constant<br>
$<span class="math notranslate nohighlight">\(\text{boxcar}(x) = (b - a)Af(a, b; x) = A(H(x - a) - H(x - b))\)</span><span class="math notranslate nohighlight">\(
\)</span>A<span class="math notranslate nohighlight">\( is a constant&lt;br&gt;
\)</span>f(a, b; x)<span class="math notranslate nohighlight">\( is the uniform distribution of \)</span>x<span class="math notranslate nohighlight">\( for the interval \)</span>[a, b]<span class="math notranslate nohighlight">\(&lt;br&gt;
\)</span>H(x)$ is the Heaviside step function<br></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4001</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">a</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">b</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">x</span> <span class="o">&lt;</span> <span class="n">a</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="n">b</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/mathematical_foundations_201_0.png" src="../_images/mathematical_foundations_201_0.png" />
</div>
</div>
<p><strong>Natural Logarithm</strong><br></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1001</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">1</span><span class="o">-</span><span class="n">a8f37b31e5cb</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1001</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>

<span class="ne">NameError</span>: name &#39;np&#39; is not defined
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<hr class="docutils" />
</div>
<hr class="docutils" />
<div class="section" id="resources">
<h1>Resources<a class="headerlink" href="#resources" title="Permalink to this headline">¶</a></h1>
<p>Goodfellow, Ian, Yoshua Bengio, &amp; Aaron Courville. (2016). <em>Deep Learning</em>. MIT Press. <a class="reference external" href="https://www.deeplearningbook.org">Home</a>.<br></p>
<p>Hastie, Trevor, Robert Tibshirani, &amp; Jerome Friedman. (2009). <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction, 2nd Ed</em>. Springer Series in Statistics. <a class="reference external" href="https://web.stanford.edu/~hastie/ElemStatLearn/">Home</a>.<br></p>
<p>Tan, Pang-Ning et al. (2019). <em>Introduction to Data Mining, 2nd Ed</em>. Pearson. <a class="reference external" href="https://www-users.cs.umn.edu/~kumar001/dmbook/index.php">Home</a>.<br></p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Definite_symmetric_matrix">https://en.wikipedia.org/wiki/Definite_symmetric_matrix</a><br>
<a class="reference external" href="https://en.wikipedia.org/wiki/Matrix_calculus">https://en.wikipedia.org/wiki/Matrix_calculus</a><br>
<a class="reference external" href="https://en.wikipedia.org/wiki/Functional_derivative">https://en.wikipedia.org/wiki/Functional_derivative</a><br>
<a class="reference external" href="https://en.wikipedia.org/wiki/Optimality_criterion">https://en.wikipedia.org/wiki/Optimality_criterion</a><br>
<a class="reference external" href="https://en.wikipedia.org/wiki/Residual_sum_of_squares">https://en.wikipedia.org/wiki/Residual_sum_of_squares</a><br>
<a class="reference external" href="https://www.youtube.com/watch?v=ZUU57Q3CFOU">https://www.youtube.com/watch?v=ZUU57Q3CFOU</a><br>
<a class="reference external" href="https://www.youtube.com/watch?v=MC7l96tW8V8">https://www.youtube.com/watch?v=MC7l96tW8V8</a><br>
<a class="reference external" href="https://www.youtube.com/watch?v=Z0wELiinNVQ">https://www.youtube.com/watch?v=Z0wELiinNVQ</a><br>
<a class="reference external" href="http://www.cs.uu.nl/docs/vakken/mpr/linreg-math.pdf">http://www.cs.uu.nl/docs/vakken/mpr/linreg-math.pdf</a><br>
<a class="reference external" href="https://atmos.uw.edu/~dennis/MatrixCalculus.pdf">https://atmos.uw.edu/~dennis/MatrixCalculus.pdf</a><br></p>
<hr class="docutils" />
<hr class="docutils" />
<hr class="docutils" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># toy data</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;tid&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span>
    <span class="s1">&#39;home_owner&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Yes&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">,</span> <span class="s1">&#39;Yes&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">,</span> <span class="s1">&#39;Yes&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">],</span>
    <span class="s1">&#39;marital_status&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Single&#39;</span><span class="p">,</span> <span class="s1">&#39;Married&#39;</span><span class="p">,</span> <span class="s1">&#39;Single&#39;</span><span class="p">,</span> <span class="s1">&#39;Married&#39;</span><span class="p">,</span> <span class="s1">&#39;Divorced&#39;</span><span class="p">,</span> <span class="s1">&#39;Married&#39;</span><span class="p">,</span> <span class="s1">&#39;Divorced&#39;</span><span class="p">,</span> <span class="s1">&#39;Single&#39;</span><span class="p">,</span> <span class="s1">&#39;Married&#39;</span><span class="p">,</span> <span class="s1">&#39;Single&#39;</span><span class="p">],</span>
    <span class="s1">&#39;annual_income&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">125e3</span><span class="p">,</span> <span class="mf">100e3</span><span class="p">,</span> <span class="mf">70e3</span><span class="p">,</span> <span class="mf">120e3</span><span class="p">,</span> <span class="mf">95e3</span><span class="p">,</span> <span class="mf">60e3</span><span class="p">,</span> <span class="mf">220e3</span><span class="p">,</span> <span class="mf">85e3</span><span class="p">,</span> <span class="mf">75e3</span><span class="p">,</span> <span class="mf">90e3</span><span class="p">],</span>
    <span class="s1">&#39;defaulted_borrower&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;No&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">,</span> <span class="s1">&#39;Yes&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">,</span> <span class="s1">&#39;Yes&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">,</span> <span class="s1">&#39;Yes&#39;</span><span class="p">],</span>
<span class="p">}</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>tid</th>
      <th>home_owner</th>
      <th>marital_status</th>
      <th>annual_income</th>
      <th>defaulted_borrower</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Yes</td>
      <td>Single</td>
      <td>125000.0</td>
      <td>No</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>No</td>
      <td>Married</td>
      <td>100000.0</td>
      <td>No</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>No</td>
      <td>Single</td>
      <td>70000.0</td>
      <td>No</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Yes</td>
      <td>Married</td>
      <td>120000.0</td>
      <td>No</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>No</td>
      <td>Divorced</td>
      <td>95000.0</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>No</td>
      <td>Married</td>
      <td>60000.0</td>
      <td>No</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>Yes</td>
      <td>Divorced</td>
      <td>220000.0</td>
      <td>No</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8</td>
      <td>No</td>
      <td>Single</td>
      <td>85000.0</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>8</th>
      <td>9</td>
      <td>No</td>
      <td>Married</td>
      <td>75000.0</td>
      <td>No</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10</td>
      <td>No</td>
      <td>Single</td>
      <td>90000.0</td>
      <td>Yes</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">P_yes</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;defaulted_borrower&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;Yes&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">P_no</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;defaulted_borrower&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;No&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">P_no</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Dave Friedman<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>