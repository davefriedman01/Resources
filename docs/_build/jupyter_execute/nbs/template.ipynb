{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ndarray' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-141dc893df60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mArray_Function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# A Function takes in an ndarray as an argument and produces an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mChain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mArray_Function\u001b[0m\u001b[0;34m]\u001b[0m                  \u001b[0;31m# A Chain is a list of functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ndarray' is not defined"
     ]
    }
   ],
   "source": [
    "from typing import\\\n",
    "    Callable,\\\n",
    "    Dict,\\\n",
    "    List\n",
    "Array_Function = Callable[[ndarray], ndarray] # A Function takes in an ndarray as an argument and produces an ndarray\n",
    "Chain = List[Array_Function]                  # A Chain is a list of functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy and Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "np.set_printoptions(precision=4)\n",
    "from numpy import ndarray\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib and Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import mpl, plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc, max\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import\\\n",
    "    DecisionTreeClassifier\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.ml.evaluation import\\\n",
    "    MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import\\\n",
    "    Binarizer,\\\n",
    "    CountVectorizer,\\\n",
    "    IDF,\\\n",
    "    IndexToString,\\\n",
    "    MinMaxScaler,\\\n",
    "    NGram,\\\n",
    "    RegexTokenizer,\\\n",
    "    SQLTransformer,\\\n",
    "    StopWordsRemover,\\\n",
    "    StringIndexer,\\\n",
    "    VectorAssembler\n",
    "from pyspark.ml.tuning import\\\n",
    "    CrossValidator,\\\n",
    "    ParamGridBuilder\n",
    "from pyspark.sql import functions as fun, Row\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp import\\\n",
    "    DocumentAssembler,\\\n",
    "    Finisher\n",
    "from sparknlp.annotator import\\\n",
    "    Lemmatizer,\\\n",
    "    LemmatizerModel,\\\n",
    "    Normalizer,\\\n",
    "    NorvigSweetingModel,\\\n",
    "    PerceptronApproach,\\\n",
    "    PerceptronModel,\\\n",
    "    SentenceDetector,\\\n",
    "    Stemmer,\\\n",
    "    SymmetricDeleteModel,\\\n",
    "    Tokenizer\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "\n",
    "#####\n",
    "#\n",
    "# this\n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "# or this\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "spark_conf = SparkConf()\n",
    "spark = SparkSession.builder.config(conf=spark_conf).getOrCreate()\n",
    "\n",
    "#\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# sm.tsa.filters.hpfilter()\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "#from statsmodels.tsa.arima.model import ARIMA\n",
    "import arch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk import ngrams\n",
    "from nltk.util import ngrams\n",
    "\n",
    "from nltk.corpus import inaugural, reuters, stopwords\n",
    "#stopwords.words('english')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer, sent_tokenize, word_tokenize\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson import ToneAnalyzerV3\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "tone_api = '0R866-tePJfMWni9gl454-jWDOS44kvX12Te4KZFe6Wr'\n",
    "tone_url = 'https://api.us-east.tone-analyzer.watson.cloud.ibm.com/instances/fc8d2c71-5116-43ab-8c9a-de4a584aa663'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "#\n",
    "# python-dotenv\n",
    "#\n",
    "#####\n",
    "from dotenv import find_dotenv, get_key\n",
    "\n",
    "alpaca_api_key = get_key(find_dotenv(), 'ALPACA_API_KEY')\n",
    "alpaca_secret_key = get_key(find_dotenv(), 'ALPACA_SECRET_KEY')\n",
    "\n",
    "news_api_key = get_key(find_dotenv(), 'NEWSAPI_API_KEY')\n",
    "\n",
    "quandl_api_key = get_key(find_dotenv(), 'QUANDL_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "#\n",
    "# configparser\n",
    "#\n",
    "#####\n",
    "import configparser\n",
    "c = configparser.ConfigParser()\n",
    "c.read('api.cfg')\n",
    "\n",
    "alpaca_api_key = c['alpaca']['api_key']\n",
    "alpaca_secret_key = c['alpaca']['secret_key']\n",
    "\n",
    "news_api_key = c['newsapi']['api_key']\n",
    "\n",
    "quandl_api_key = c['quandl']['api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alpaca_trade_api as tradeapi\n",
    "api = tradeapi.REST(\n",
    "    alpaca_api_key,\n",
    "    alpaca_secret_key,\n",
    "    api_version='v2',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl as q\n",
    "q.ApiConfig.api_key = quandl_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsapi import NewsApiClient\n",
    "newsapi = NewsApiClient(api_key=news_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from collections import Counter, OrderedDict\n",
    "from datetime import datetime, timedelta\n",
    "import itertools as it\n",
    "import json\n",
    "from operator import add, concat, itemgetter, methodcaller\n",
    "import string\n",
    "import re\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}